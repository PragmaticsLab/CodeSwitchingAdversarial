{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entire-discrimination",
   "metadata": {},
   "source": [
    "# PLAN\n",
    "\n",
    " - Диалоговый датасет\n",
    "     - BANKING77\n",
    "     - CLINC150\n",
    "     - HWU64\n",
    "     - https://github.com/google-research-datasets/dstc8-schema-guided-dialogue\n",
    " - Генератор (XLM-R)\n",
    "     - придумать как генерировать токен на другом языке\n",
    "     - применить к задачке\n",
    " - LABSE для полученных и исходных предложений\n",
    "     - сделать кастомный класс лосса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-immune",
   "metadata": {},
   "source": [
    "Для XLM-R:\n",
    "\n",
    "Занулить веса на выходе для всех языков кроме русского (пройтись по всем токенам и регулярочкой выявить те токены, которые относятся к русскому). Перед backward занулять градиенты по всем токенам не из русского, ибо торч не даст ставить requires_grad на отдельную часть тензора.\n",
    "\n",
    "Как вариант - написать обертку над моделью, которая будет иметь меньший размер выходной головы, потом делать новый тензор с нулями на месте других языков и выходом модели для русского."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-lotus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T11:39:59.794931Z",
     "start_time": "2021-02-13T11:39:57.710363Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "\n",
    "sns.set(style='darkgrid', rc={'figure.figsize': (16, 9)})\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thick-dance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T12:35:35.137547Z",
     "start_time": "2021-02-13T12:35:34.992005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61767, 46)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/dstc_utterances.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts, intents = zip(*((elem['text'], elem['intent']) for elem in data))\n",
    "\n",
    "len(texts), len(np.unique(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "systematic-iraqi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T12:35:35.756333Z",
     "start_time": "2021-02-13T12:35:35.750853Z"
    }
   },
   "outputs": [],
   "source": [
    "lens = [len(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rough-harvest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T12:36:01.751131Z",
     "start_time": "2021-02-13T12:36:01.475080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unable-restaurant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T11:40:16.805913Z",
     "start_time": "2021-02-13T11:40:00.726705Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model_name = 'xlm-roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "specialized-rochester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:02:23.331852Z",
     "start_time": "2021-02-13T14:02:23.328964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1630,  0.1508,  0.1604,  ...,  0.1351,  0.1860,  0.0673],\n",
       "        [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078],\n",
       "        [ 0.2046,  0.2549,  0.1329,  ...,  0.1738,  0.0246,  0.2510],\n",
       "        ...,\n",
       "        [ 0.3828, -0.4441,  0.1398,  ...,  0.2268,  0.0560,  0.1038],\n",
       "        [ 0.0205, -0.1243,  0.0191,  ..., -0.0143,  0.0376, -0.1144],\n",
       "        [ 0.1009,  0.0588,  0.0551,  ...,  0.1232, -0.0064,  0.1216]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "polar-broadway",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:03:19.762669Z",
     "start_time": "2021-02-13T14:03:19.760841Z"
    }
   },
   "outputs": [],
   "source": [
    "c = torch.stack((a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "desperate-planning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:04:14.052403Z",
     "start_time": "2021-02-13T14:04:14.050851Z"
    }
   },
   "outputs": [],
   "source": [
    "emb = model.roberta.embeddings.word_embeddings.weight[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "confirmed-roman",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:04:14.585771Z",
     "start_time": "2021-02-13T14:04:14.583855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 100]), torch.Size([2, 100, 768]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "revolutionary-premiere",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:04:21.177469Z",
     "start_time": "2021-02-13T14:04:21.175883Z"
    }
   },
   "outputs": [],
   "source": [
    "emb[c == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "visible-chemistry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:04:25.079999Z",
     "start_time": "2021-02-13T14:04:25.077056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0908, -0.1393, -0.0595,  ...,  0.1466, -0.0898,  0.2864],\n",
       "         [ 0.0435,  0.4148, -0.3076,  ...,  0.3025,  0.0803, -0.0367],\n",
       "         ...,\n",
       "         [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078],\n",
       "         [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078],\n",
       "         [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0908, -0.1393, -0.0595,  ...,  0.1466, -0.0898,  0.2864],\n",
       "         [ 0.0435,  0.4148, -0.3076,  ...,  0.3025,  0.0803, -0.0367],\n",
       "         ...,\n",
       "         [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078],\n",
       "         [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078],\n",
       "         [-0.0073,  0.0048, -0.0078,  ...,  0.0078,  0.0041, -0.0078]]],\n",
       "       grad_fn=<IndexPutBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daily-automation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:02:40.786441Z",
     "start_time": "2021-02-13T14:02:40.784025Z"
    }
   },
   "outputs": [],
   "source": [
    "a = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt', max_length=100, padding='max_length').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lucky-receptor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:08:24.079542Z",
     "start_time": "2021-02-13T08:08:22.697094Z"
    }
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def is_cyrillic(s: str):\n",
    "    return bool(regex.search(r'\\p{IsCyrillic}', s))\n",
    "\n",
    "\n",
    "russian_tokens_mask = np.zeros(model.lm_head.decoder.weight.shape[0])\n",
    "\n",
    "for token in range(model.lm_head.decoder.weight.shape[0]):\n",
    "    if is_cyrillic(tokenizer.decode([token])):\n",
    "        russian_tokens_mask[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "communist-arcade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:08:26.012140Z",
     "start_time": "2021-02-13T08:08:26.010616Z"
    }
   },
   "outputs": [],
   "source": [
    "russian_tokens_mask = russian_tokens_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graphic-sellers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:08:27.153352Z",
     "start_time": "2021-02-13T08:08:27.151314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_tokens_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conceptual-conflict",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:08:30.938037Z",
     "start_time": "2021-02-13T08:08:30.894337Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.lm_head.decoder.weight[~russian_tokens_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "protecting-updating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:55:56.435053Z",
     "start_time": "2021-02-13T08:55:56.282812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = f'I have a {tokenizer.mask_token}'\n",
    "\n",
    "inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
    "mask_token_index = torch.where(inputs == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(inputs).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "tokenizer.decode([torch.argmax(mask_token_logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "conservative-colon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:59:38.945129Z",
     "start_time": "2021-02-13T08:59:28.870694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lesha/.local/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:966: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "sequence = f\"I went fishing and I {tokenizer.mask_token} several big fish.\"\n",
    "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "assumed-porcelain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:01:25.903105Z",
     "start_time": "2021-02-13T09:01:15.943187Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "elect-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:02:36.758987Z",
     "start_time": "2021-02-13T09:02:29.490075Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/xlm-roberta-base.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "extraordinary-collection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:59:38.948156Z",
     "start_time": "2021-02-13T08:59:38.945974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went fishing and I caught several big fish.\n",
      "I went fishing and I saw several big fish.\n",
      "I went fishing and I found several big fish.\n",
      "I went fishing and I got several big fish.\n",
      "I went fishing and I had several big fish.\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "friendly-algorithm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:35:38.016118Z",
     "start_time": "2021-02-13T08:35:38.013569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         ...,\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "finite-reach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:37:27.658813Z",
     "start_time": "2021-02-13T08:37:27.657187Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "limiting-group",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:38:12.556829Z",
     "start_time": "2021-02-13T08:38:12.553264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(inputs.shape[0], 250002).scatter_(1, inputs, 1.0)[inputs.flatten() == tokenizer.mask_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "thirty-bearing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:38:09.498202Z",
     "start_time": "2021-02-13T08:38:09.495607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([False, False, False, False,  True, False, False, False])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inputs.flatten() == tokenizer.mask_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abandoned-labor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:14:08.098411Z",
     "start_time": "2021-02-13T08:14:08.096560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 250002])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "wrong-deputy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:20:34.395579Z",
     "start_time": "2021-02-13T08:20:34.286616Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor = torch.LongTensor([1, 2, 3]).reshape(-1, 1)\n",
    "\n",
    "y = torch.zeros(len(tensor), 250002).scatter_(1, tensor, 1.0) @ model.roberta.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outer-spain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:09:49.316982Z",
     "start_time": "2021-02-13T08:09:49.277564Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_output = one_hot @ model.roberta.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aquatic-enhancement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:20:37.402986Z",
     "start_time": "2021-02-13T08:20:37.401164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "inside-expert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:19:20.413030Z",
     "start_time": "2021-02-13T08:19:20.407930Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-18d0e326655d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "y[tensor == 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "russian-symphony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:19:44.138242Z",
     "start_time": "2021-02-13T08:19:44.136356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 768]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "elder-bullet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:21:01.467681Z",
     "start_time": "2021-02-13T08:21:01.465784Z"
    }
   },
   "outputs": [],
   "source": [
    "y = torch.zeros(len(tensor), 250002).scatter_(1, tensor, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abroad-clothing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:21:49.585592Z",
     "start_time": "2021-02-13T08:21:49.578331Z"
    }
   },
   "outputs": [],
   "source": [
    "y[tensor.flatten() == 3] = torch.nn.functional.gumbel_softmax(mask_token_logits, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bound-expert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:21:53.889437Z",
     "start_time": "2021-02-13T08:21:53.886981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<IndexPutBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "headed-scheduling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:17:03.405171Z",
     "start_time": "2021-02-13T08:17:03.403174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "legendary-dutch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:17:08.581241Z",
     "start_time": "2021-02-13T08:17:08.492078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836],\n",
       "         [ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(inputs_embeds=y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "accurate-federal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T08:17:49.733161Z",
     "start_time": "2021-02-13T08:17:49.639152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836]],\n",
       "\n",
       "        [[ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836]],\n",
       "\n",
       "        [[ 0.4143, -0.0156,  0.2747,  ...,  0.1248,  0.1586, -0.0836]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(input_ids=tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "central-short",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:35:00.859281Z",
     "start_time": "2021-02-11T16:35:00.851315Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = inputs.float()\n",
    "outputs[inputs == tokenizer.mask_token_id] = torch.sum(torch.nn.functional.gumbel_softmax(mask_token_logits, hard=True) * torch.arange(0, mask_token_logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "productive-prototype",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:35:01.207968Z",
     "start_time": "2021-02-11T16:35:01.205645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,  87., 765.,  10., 983.,   6.,   5.,   2.]],\n",
       "       grad_fn=<IndexPutBackward>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "smart-woman",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:35:02.899747Z",
     "start_time": "2021-02-11T16:35:02.898262Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs2 = outputs.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "synthetic-static",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:35:41.514662Z",
     "start_time": "2021-02-11T16:35:41.512614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IndexPutBackward at 0x7fa80df76580>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "wireless-silly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:35:49.116323Z",
     "start_time": "2021-02-11T16:35:49.110502Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "attribute 'grad_fn' of 'torch._C._TensorBase' objects is not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-178a35c66f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: attribute 'grad_fn' of 'torch._C._TensorBase' objects is not writable"
     ]
    }
   ],
   "source": [
    "outputs2.grad_fn = outputs.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "every-demographic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:34:32.324349Z",
     "start_time": "2021-02-11T16:34:32.322942Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "systematic-pledge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:28:49.064502Z",
     "start_time": "2021-02-11T16:28:49.062433Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
    "mask_token_index = torch.where(inputs == tokenizer.mask_token_id)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "charming-dining",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:29:12.333397Z",
     "start_time": "2021-02-11T16:29:12.316782Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index put requires the source and destination dtypes match, got Long for the destination and Float for the source.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-04426102ad6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgumbel_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_token_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_token_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Index put requires the source and destination dtypes match, got Long for the destination and Float for the source."
     ]
    }
   ],
   "source": [
    "inputs[inputs == tokenizer.mask_token_id] = torch.sum(torch.nn.functional.gumbel_softmax(mask_token_logits, hard=True) * torch.arange(0, mask_token_logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "turkish-shareware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:27:59.542256Z",
     "start_time": "2021-02-11T16:27:59.539202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 8.7000e+01, 7.6500e+02, 1.0000e+01, 2.0384e+05, 6.0000e+00,\n",
       "         5.0000e+00, 2.0000e+00]], grad_fn=<IndexPutBackward>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "right-integration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T16:25:31.233120Z",
     "start_time": "2021-02-11T16:25:31.231193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tired-senegal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T17:22:59.218939Z",
     "start_time": "2021-02-12T17:22:59.173979Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom loss counting similarity between target and output sentence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_name = 'sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens'\n",
    "        self.model = AutoModel.from_pretrained(self.model_name).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        outputs_1 = self.model(**outputs)\n",
    "        outputs_2 = self.model(**labels)\n",
    "\n",
    "        embeddings_1 = outputs_1.pooler_output\n",
    "        embeddings_2 = outputs_2.pooler_output\n",
    "\n",
    "        normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
    "        normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
    "\n",
    "        return normalized_embeddings_1 @ normalized_embeddings_2.transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "designed-museum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T17:23:15.798595Z",
     "start_time": "2021-02-12T17:23:11.258692Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens'\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dental-importance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T17:23:32.445045Z",
     "start_time": "2021-02-12T17:23:32.443082Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.to_json_file('../models/xmr-roberta-base-mean-tokens.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "binary-placement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:36:42.353855Z",
     "start_time": "2021-02-13T09:36:38.961668Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel, PretrainedConfig\n",
    "\n",
    "model = XLMRobertaModel(PretrainedConfig.from_json_file('../models/xlm-roberta-base-mean-tokens.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "inappropriate-worth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:36:46.912693Z",
     "start_time": "2021-02-13T09:36:46.558030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/xlm-roberta-base-mean-tokens.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "enabling-musical",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:36:47.515682Z",
     "start_time": "2021-02-13T09:36:47.512327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "stock-rolling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:52:36.863646Z",
     "start_time": "2021-02-11T15:50:51.419816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0149b7fe1d4f8c9833957aec2b93d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1112256686.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss = CustomLoss(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "elect-foster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:53:47.205961Z",
     "start_time": "2021-02-11T15:53:45.306289Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "interpreted-optics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:47:44.370535Z",
     "start_time": "2021-02-13T09:47:44.364213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0416,  0.0110, -0.0000,  ...,  0.0000, -0.1096, -0.0141],\n",
       "         [ 0.0631, -0.6998, -0.5704,  ..., -0.1152, -0.4210,  0.5102],\n",
       "         [-0.1585,  0.0000, -0.7146,  ...,  0.6517,  0.3447, -0.1969],\n",
       "         ...,\n",
       "         [-0.0000, -0.1132, -0.4343,  ...,  1.0054, -0.0928, -0.0329],\n",
       "         [ 0.1366,  0.8943,  0.0611,  ...,  0.0495, -0.3360, -0.6585],\n",
       "         [ 0.0166,  0.1572,  0.0089,  ...,  0.0337,  0.0542, -0.1161]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt')\n",
    "\n",
    "model.embeddings(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "tough-nursing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:47:45.325211Z",
     "start_time": "2021-02-13T09:47:45.321214Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1, 1)\n",
    "\n",
    "tokens_one_hot = torch.zeros(inputs.shape[0], 250002).scatter_(\n",
    "    1, inputs, 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "third-gravity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:47:45.897186Z",
     "start_time": "2021-02-13T09:47:45.818972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0416,  0.0000, -0.0678,  ...,  0.0280, -0.1096, -0.0141],\n",
       "         [ 0.0631, -0.6998, -0.5704,  ..., -0.1152, -0.4210,  0.5102],\n",
       "         [-0.1585,  0.4480, -0.7146,  ...,  0.6517,  0.3447, -0.1969],\n",
       "         ...,\n",
       "         [-0.8030, -0.1132, -0.4343,  ...,  1.0054, -0.0928, -0.0329],\n",
       "         [ 0.1366,  0.8943,  0.0611,  ...,  0.0000, -0.3360, -0.6585],\n",
       "         [ 0.0166,  0.1572,  0.0089,  ...,  0.0337,  0.0542, -0.1161]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.forward(inputs_embeds=(tokens_one_hot @ model.embeddings.word_embeddings.weight).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "speaking-second",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:48:20.833661Z",
     "start_time": "2021-02-13T09:48:20.758772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(model.embeddings(inputs), model.embeddings.forward(inputs_embeds=(tokens_one_hot @ model.embeddings.word_embeddings.weight).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "local-vulnerability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:28.581453Z",
     "start_time": "2021-02-13T09:51:28.518050Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt')\n",
    "    \n",
    "    x = model.embeddings(inputs)\n",
    "    \n",
    "    inputs = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt').reshape(-1, 1)\n",
    "\n",
    "    tokens_one_hot = torch.zeros(inputs.shape[0], 250002).scatter_(\n",
    "        1, inputs, 1.0\n",
    "    )\n",
    "    \n",
    "    y = model.embeddings.forward(inputs_embeds=(tokens_one_hot @ model.embeddings.word_embeddings.weight).unsqueeze(0))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "confirmed-ethnic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:30.257545Z",
     "start_time": "2021-02-13T09:51:30.255685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "electric-gauge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:31.044750Z",
     "start_time": "2021-02-13T09:51:31.042902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "minimal-integer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:31.736178Z",
     "start_time": "2021-02-13T09:51:31.733907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((x == y).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-hunger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "diploma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
