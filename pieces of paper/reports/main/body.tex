\subsection{Обучение моделей на датасете ATIS seven languages}
В своей работе мы обучаем языковые модели решать задачу одновременной классификации интентов и разметки слотов в предложении.
Эта задача заключается в определении желаемой цели запроса пользователя по предложению и классификации слов в предложении.

\subsubsection{Датасет}
В качестве датасета в своей работе мы выбрали датасет ATIS seven languages~\cite{Xu2020EndtoEndSA}.
В этом датасете представлены семь языков из трёх языковых семей —
Индо-Европейская (английский, немецкий, французский, испанский, португальский), Японо-рюкюская (японский) и Сино-тибетская (китайский).
Датасет является параллельным корпусом для задачи классификации интентов и разметки слотов - в 2020 году он был переведён с английского языка на остальные шесть.
В обучающей выборке содержится 4978 предложений для каждого языка, в тестовой 893 предложения для каждого языка.
\parКаждый объект в датасете состоит из предложения, меток слов и интента.
Перед началом работы с датасетом мы произвели предварительную очистку —
убрали из обучающей и тестовой выборок объекты, для которых на любом из семи языков количество слов и количество слотов не совпадали.
Таким образом, в обучающей выборке осталось 4884 объекта для каждого языка, в тестовой выборке 755 объектов для каждого языка.
Для составления списка используемых слотов и интентов использовалась обучающая выборка на английском языке.
Мы использовали 121 различную метку слотов и 23 различных метки интентов.
Список id используемых объектов, а также списки используемых слотов и интентов можно найти в приложении.

\subsubsection{Архитектура модели}
В своей работе мы решаем задачу одновременной классификации интентов и разметки слотов в предложении с помощью одной модели.
Модель имеет два выхода, первый предсказывает интенты, второй предсказывает метки слов.
В качестве рассматриваемых архитектур были выбраны модели m-BERT~\cite{devlin-etal-2019-bert} и XLM-RoBERTa~\cite{Conneau2020UnsupervisedCR}.
Обе эти модели являются одними из самых сильных мультиязычных моделей на текущий момент.
Каждая из них предобучена на более чем ста языках.
% TODO: дописать про размеры моделей.

\subsubsection{Обучение}
В своей работе мы будем сравнивать модели, обученные на всей обучающей выборке и только на части обучающей выборки на английском языке.
Таким образом мы сможем проверить гипотезу о наличии кросс-язычных знаний у моделей.
Тестовая выборка, которая будет нас интересовать в данном контексте состоит из всех семи языков, но мы оцениваем качество на каждом языке отдельно.
\parКаждая из моделей обучалась с одинаковыми гиперпараметрами - 10 эпох на обучающей выборке с длиной шага обучения $10^{-5}$ и размером батча в 64 объекта.
%В качестве функции ошибки использовалась кросс-энтропия:
% TODO: дописать про лосс.

\parВ своей работе мы будем использовать следующие метрики качества:
\begin{itemize}
    \item Доля правильных ответов для интентов:
    \begin{equation}
        \textbf{Intent accuracy}(x, y) = \dfrac{1}{N} \sum_{i = 1}^{N} [x_i = y_i]\label{eq:equation}
    \end{equation}
    \item F1 мера для меток слотов:
    \begin{equation}
        \textbf{Slots F1 score} = 2 \cdot \dfrac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}\label{eq:equation2}
    \end{equation}
    \item Доля предложений, в которых правильно классифицирован интент и верно классифицированы все слоты:
    \begin{equation}
        \textbf{Semantic accuracy} = \# sentences [ \left(I_{pred} = I_{true} \right) \land \left(S_{pred} = S_{true} \right)]\label{eq:equation3}
    \end{equation}
\end{itemize}
% TODO: добавить графики обучения.

\subsection{Адверсариальные атаки}
В своей работе мы предлагаем два варианта gray-box адверсариальных атак — во время выполнения атаки мы имеем доступ к ошибке модели.
Мы стремимся создать атаку такого рода, чтобы результирующая адверсариальная пертурбация предложения была как можно ближе к реалистичным предложениям со смешением кодов.
Для этого мы заменяем часть токенов в предложении на их эквиваленты из других языков.
Оценка качества на таких адверсариальных атаках может выступать в роли оценки снизу на качество соответствующих моделей в аналогичных задачах при наличии реального смешения кодов во входных данных. \\
Так как большинство людей, которые могут использовать смешение кодов в своей речи билингвы, то в основном смешение кодов происходит между парой языков~\cite{bilinguals}.
Таким образом, в своей работе мы предлагаем анализировать атаки состоящие во встраивании одного языка в другой.

\subsubsection{Общий вид атаки}
Общий принцип атаки одинаковый для обоих предлагаемых вариантов.
Разница между методами заключается в способе генерации кандидатов на замену токену на $i-$ой позиции.
В своей работе мы предлагаем следующий вид атаки — пусть мы имеем целевую модель, пару пример-метка и встраиваемый язык~\eqref{alg:algorithm}.
Тогда мы перебираем токены в предложении в случайном порядке и стремимся заменить токен на его эквивалент из встраиваемого языка.
Если это приведёт к увеличению ошибки модели, то мы заменяем токен на предложенного кандидата.

\begin{algorithm}
    \caption{Адверсариальная атака, общая схема}
    \begin{algorithmic}
        \Require{Пара пример-метка x, y; целевая модель $\mathcal{M}$; встраиваемый язык $\mathbb{L}$}
        \Ensure{Адверсариальный пример $x'$} \\
        $\mathcal{L}_{x}$ = GetLoss($\mathcal{M}$, x, y)
        \For{i in permutation(len(x))}
            \\
            \ind Candidates = GetCandidates($\mathcal{M}$, x, y, token\_id = i) \\
            \ind Losses = GetLoss($\mathcal{M}$, Candidates)
            \ind\If{Candidates and max(Losses) > $\mathcal{L}_{x}$}
                    \\
                    \ind\ind$\mathcal{L}_{x}$ = max(Losses) \\
                    \ind\ind x, y = Candidates[argmax(Losses)]
            \EndIf
        \EndFor \\
        \ind\Return x
    \end{algorithmic}\label{alg:algorithm}
\end{algorithm}

\subsubsection{Word level атака}
Первый предлагаемый нами вариант атаки заключается в генерации эквивалентов из других языков с помощью перевода токенов на соответствующие языки.
Этот вариант является грубой оценкой снизу, так как он не учитывает контекста предложений и не учитывает многозначность слов. \\
Для перевода слов на другие языки мы используем модель машинного перевода M2M 100 от компании Facebook ~\cite{Fan2020BeyondEM}.
Она содержит 418 миллионов параметров.

\begin{algorithm}
    \caption{Word-level атака}
    \begin{algorithmic}
        \Require{Словарь переводов с исходного на встраиваемый язык $\mathbb{T}$}
        \Function{GetCandidates}{$\mathcal{M}$, x, y, token\_id}
            \ind\If{x[token\_id] in $\mathbb{T}[\mathbb{L}]$}
                    \\
                    \ind\ind tokens = $\mathbb{T}[\mathbb{L}]$[x[token\_id]]\\
                    \ind\ind x[token\_id] = tokens\\
                    \ind\ind y[token\_id] = ExtendSlotLabels(y[token\_id], len(tokens))
            \EndIf \\
            \ind\Return x, y
        \EndFunction
    \end{algorithmic}\label{alg:algorithm1}
\end{algorithm}

% TODO: пример атаки.

\subsubsection{Phrase-level атака}
Второй предлагаемый нами вариант атаки заключается в генерации эквивалентов из других языков с помощью построения выравниваний между предложениями на разных языков.
Кандидаты для каждого токена определяются как токены из предложения на встраиваемом языке, в которые был выровнен токен. \\
Для построения выравниваний мы используем модель awesome-align на основе m-BERT~\cite{Dou2021WordAB}.

\begin{algorithm}
    \caption{Word-level атака}
    \begin{algorithmic}
        \Require{Выравнивание предложения на исходном языке к предложению на целевом языке $\mathbb{A}$}
        \Function{GetCandidates}{$\mathcal{M}$, x, y, token\_id}
            \ind\If{x[token\_id] in $\mathbb{A}[\mathbb{L}]$}
                    \\
                    \ind\ind tokens = $\mathbb{A}[\mathbb{L}]$[x[token\_id]]\\
                    \ind\ind x[token\_id] = tokens\\
                    \ind\ind y[token\_id] = ExtendSlotLabels(y[token\_id], len(tokens))
            \EndIf \\
            \ind\Return x, y
        \EndFunction
    \end{algorithmic}\label{alg:algorithm2}
\end{algorithm}

% TODO: пример атаки.

\subsection{Метод защиты от адверсариальных атак}
В своей работе мы предлагаем метод защиты от предложенных выше адверсариальных атак.
Гипотеза заключается в том, что данный метод позволит увеличить качество не только на адверсариальных пертурбациях, но и на реальных данных со смешением кодов.

\subsubsection{Метод адверсариального предобучения}

\subsection{Результаты}

% TODO: написать текст про результаты сравнения.

\subsubsection{Кросс-язычные знания в моделях}

% TODO: написать текст про знания, на основе таблиц.

\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & xlm-r   & xlm-r en & xlm-r adv & xlm-r en + adv \\ \hline
            Intent accuracy   & $0.980$ & $0.902$  & $0.981$   & $0.928$        \\ \hline
            Slot F1 score     & $0.944$ & $0.870$  & $0.947$   & $0.888$        \\ \hline
            Semantic accuracy & $0.826$ & $0.559$  & $0.833$   & $0.613$        \\ \hline
            Loss              & $0.317$ & $0.729$  & $0.320$   & $0.621$        \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей XLM-R между собой на тестовой выборке (английский язык)}\label{tab:table}
\end{table}
\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & m-bert  & m-bert en & m-bert adv & m-bert en + adv \\ \hline
            Intent accuracy   & $0.979$ & $0.952$   & $0.975$    & $0.959$         \\ \hline
            Slot F1 score     & $0.947$ & $0.899$   & $0.950$    & $0.900$         \\ \hline
            Semantic accuracy & $0.854$ & $0.672$   & $0.861$    & $0.674$         \\ \hline
            Loss              & $0.353$ & $0.584$   & $0.326$    & $0.567$         \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей M-BERT между собой на тестовой выборке (английский язык)}\label{tab:table2}
\end{table}
\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & xlm-r             & xlm-r en          & xlm-r adv         & xlm-r en + adv    \\ \hline
            Intent accuracy   & $0.969 \pm 0.004$ & $0.840 \pm 0.044$ & $0.970 \pm 0.004$ & $0.860 \pm 0.043$ \\ \hline
            Slot F1 score     & $0.928 \pm 0.011$ & $0.669 \pm 0.063$ & $0.930 \pm 0.013$ & $0.675 \pm 0.113$ \\ \hline
            Semantic accuracy & $0.775 \pm 0.044$ & $0.181 \pm 0.107$ & $0.781 \pm 0.048$ & $0.245 \pm 0.167$ \\ \hline
            Loss              & $0.399 \pm 0.055$ & $1.498 \pm 0.368$ & $0.409 \pm 0.063$ & $1.453 \pm 0.525$ \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей XLM-R между собой на тестовой выборке (все языки кроме английского)}\label{tab:table3}
\end{table}
\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & m-bert            & m-bert en         & m-bert adv        & m-bert en + adv   \\ \hline
            Intent accuracy   & $0.964 \pm 0.008$ & $0.828 \pm 0.043$ & $0.967 \pm 0.006$ & $0.837 \pm 0.072$ \\ \hline
            Slot F1 score     & $0.927 \pm 0.020$ & $0.616 \pm 0.093$ & $0.929 \pm 0.015$ & $0.576 \pm 0.101$ \\ \hline
            Semantic accuracy & $0.776 \pm 0.064$ & $0.204 \pm 0.103$ & $0.779 \pm 0.055$ & $0.219 \pm 0.117$ \\ \hline
            Loss              & $0.425 \pm 0.093$ & $1.584 \pm 0.348$ & $0.382 \pm 0.057$ & $1.794 \pm 0.768$ \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей M-BERT между собой на тестовой выборке (все языки кроме английского)}\label{tab:table4}
\end{table}

\subsubsection{Качество моделей после адверсариальных атак}

\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & xlm-r             & xlm-r en          & xlm-r adv         & xlm-r en + adv    \\ \hline
            Intent accuracy   & $0.876 \pm 0.034$ & $0.721 \pm 0.086$ & $0.888 \pm 0.033$ & $0.769 \pm 0.079$ \\ \hline
            Slot F1 score     & $0.642 \pm 0.083$ & $0.550 \pm 0.068$ & $0.640 \pm 0.088$ & $0.554 \pm 0.076$ \\ \hline
            Semantic accuracy & $0.177 \pm 0.101$ & $0.065 \pm 0.063$ & $0.174 \pm 0.102$ & $0.101 \pm 0.070$ \\ \hline
            Loss              & $2.662 \pm 0.737$ & $3.234 \pm 0.807$ & $2.553 \pm 0.669$ & $2.905 \pm 0.562$ \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей XLM-R после word-level атаки}\label{tab:table5}
\end{table}
\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & m-bert            & m-bert en         & m-bert adv        & m-bert en + adv   \\ \hline
            Intent accuracy   & $0.863 \pm 0.025$ & $0.771 \pm 0.028$ & $0.893 \pm 0.017$ & $0.819 \pm 0.047$ \\ \hline
            Slot F1 score     & $0.553 \pm 0.098$ & $0.447 \pm 0.084$ & $0.581 \pm 0.085$ & $0.455 \pm 0.069$ \\ \hline
            Semantic accuracy & $0.117 \pm 0.075$ & $0.055 \pm 0.051$ & $0.155 \pm 0.085$ & $0.081 \pm 0.054$ \\ \hline
            Loss              & $3.169 \pm 0.689$ & $3.338 \pm 0.667$ & $2.860 \pm 0.687$ & $2.959 \pm 0.574$ \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей M-BERT после word-level атаки}\label{tab:table6}
\end{table}
\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & xlm-r             & xlm-r en          & xlm-r adv         & xlm-r en + adv    \\ \hline
            Intent accuracy   & $0.949 \pm 0.011$ & $0.727 \pm 0.131$ & $0.952 \pm 0.011$ & $0.827 \pm 0.035$ \\ \hline
            Slot F1 score     & $0.708 \pm 0.139$ & $0.584 \pm 0.111$ & $0.716 \pm 0.147$ & $0.621 \pm 0.146$ \\ \hline
            Semantic accuracy & $0.368 \pm 0.161$ & $0.106 \pm 0.071$ & $0.392 \pm 0.156$ & $0.214 \pm 0.133$ \\ \hline
            Loss              & $2.032 \pm 1.156$ & $2.860 \pm 0.839$ & $2.032 \pm 1.233$ & $2.113 \pm 0.637$ \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей XLM-R после phrase-level атаки}\label{tab:table7}
\end{table}
\begin{table}[H]
    \resizebox{\textwidth}{!}{
        \begin{tabular}{|>{\bfseries}l|c|c|c|c|}
            \hline
            & m-bert            & m-bert en         & m-bert adv        & m-bert en + adv   \\ \hline
            Intent accuracy   & $0.941 \pm 0.006$ & $0.829 \pm 0.018$ & $0.951 \pm 0.005$ & $0.847 \pm 0.054$ \\ \hline
            Slot F1 score     & $0.700 \pm 0.127$ & $0.538 \pm 0.097$ & $0.725 \pm 0.142$ & $0.578 \pm 0.132$ \\ \hline
            Semantic accuracy & $0.345 \pm 0.128$ & $0.110 \pm 0.055$ & $0.424 \pm 0.159$ & $0.214 \pm 0.116$ \\ \hline
            Loss              & $2.131 \pm 1.138$ & $2.463 \pm 0.585$ & $1.970 \pm 1.196$ & $2.159 \pm 0.755$ \\ \hline
        \end{tabular}
    }\caption{Сравнение моделей M-BERT после phrase-level атаки}\label{tab:table8}
\end{table}

\subsubsection{Влияние метода адверсариального предобучения}
