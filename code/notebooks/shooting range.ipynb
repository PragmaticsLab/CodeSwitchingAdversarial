{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entire-discrimination",
   "metadata": {},
   "source": [
    "# PLAN\n",
    "\n",
    " - Диалоговый датасет\n",
    "     - BANKING77\n",
    "     - CLINC150\n",
    "     - HWU64\n",
    "     - https://github.com/google-research-datasets/dstc8-schema-guided-dialogue\n",
    " - Генератор (XLM-R)\n",
    "     - придумать как генерировать токен на другом языке\n",
    "     - применить к задачке\n",
    " - LABSE для полученных и исходных предложений\n",
    "     - сделать кастомный класс лосса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-helping",
   "metadata": {},
   "source": [
    " - Пообучать языковую модель на частичных переводах ?\n",
    " - думать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-immune",
   "metadata": {},
   "source": [
    "Для XLM-R:\n",
    "\n",
    "Занулить веса на выходе для всех языков кроме русского (пройтись по всем токенам и регулярочкой выявить те токены, которые относятся к русскому). Перед backward занулять градиенты по всем токенам не из русского, ибо торч не даст ставить requires_grad на отдельную часть тензора.\n",
    "\n",
    "Как вариант - написать обертку над моделью, которая будет иметь меньший размер выходной головы, потом делать новый тензор с нулями на месте других языков и выходом модели для русского."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographic-lotus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:41:01.322170Z",
     "start_time": "2021-02-19T08:41:00.623835Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "\n",
    "sns.set(style='darkgrid', rc={'figure.figsize': (16, 9)})\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thick-dance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:41:01.428031Z",
     "start_time": "2021-02-19T08:41:01.323060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61767, 46)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/dstc_utterances.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts, intents = zip(*((elem['text'], elem['intent']) for elem in data))\n",
    "\n",
    "len(texts), len(np.unique(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "systematic-iraqi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:47:59.869500Z",
     "start_time": "2021-02-19T08:47:59.840806Z"
    }
   },
   "outputs": [],
   "source": [
    "lens = np.array([len(text.split()) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rough-harvest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:48:00.811907Z",
     "start_time": "2021-02-19T08:48:00.345901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "certain-queue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:41:12.031019Z",
     "start_time": "2021-02-19T08:41:06.105776Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    XLMRobertaForMaskedLM,\n",
    "    XLMRobertaModel,\n",
    "    XLMRobertaTokenizerFast,\n",
    ")\n",
    "\n",
    "\n",
    "model = XLMRobertaModel(PretrainedConfig.from_json_file(f'../models/xlm-roberta-base-mean-tokens.json'))\n",
    "model.load_state_dict(torch.load('../models/xlm-roberta-base-mean-tokens.pth'))\n",
    "\n",
    "model.to('cuda:0')\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "governmental-prescription",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:41:56.858014Z",
     "start_time": "2021-02-19T08:41:55.591077Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lucky-receptor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:42:01.749326Z",
     "start_time": "2021-02-19T08:42:00.369308Z"
    }
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def is_cyrillic(s: str):\n",
    "    return bool(regex.search(r'\\p{IsCyrillic}', s))\n",
    "\n",
    "\n",
    "russian_tokens_mask = np.zeros(model.embeddings.word_embeddings.weight.shape[0])\n",
    "\n",
    "for token in range(len(russian_tokens_mask)):\n",
    "    if is_cyrillic(tokenizer.decode([token])):\n",
    "        russian_tokens_mask[token] = 1\n",
    "\n",
    "russian_tokens_mask = russian_tokens_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "removed-choice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:48:53.137431Z",
     "start_time": "2021-02-19T08:48:53.113486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am bored of eating food from home , i need a change . Will you find me a place to eat? It can be costly priced and i am very fond of it'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(texts)[lens > 30][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "seventh-majority",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:49:53.573418Z",
     "start_time": "2021-02-19T08:49:53.525122Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    sentence = np.array(texts)[lens > 30][0]\n",
    "\n",
    "    encoding = tokenizer.encode(sentence, return_tensors='pt').to('cuda:0')\n",
    "\n",
    "    embedding = func.normalize(model(encoding).pooler_output, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "female-services",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:50:03.555106Z",
     "start_time": "2021-02-19T08:50:03.553095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'food'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding[0][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "seventh-moses",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:53:57.647502Z",
     "start_time": "2021-02-19T08:50:08.531313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31671/31671 [03:49<00:00, 138.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for token in tqdm(np.arange(0, len(russian_tokens_mask))[russian_tokens_mask]):\n",
    "        encoding[0][7] = token\n",
    "\n",
    "        new_embedding = func.normalize(model(encoding).pooler_output, p=2)\n",
    "\n",
    "        results[tokenizer.decode([token])] = (embedding @ new_embedding.transpose(0, 1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "seventh-display",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T08:57:35.407894Z",
     "start_time": "2021-02-19T08:57:35.391908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "храната 0.9978576898574829\n",
      "работите 0.9977532029151917\n",
      "врсте 0.9977286458015442\n",
      "обзавеждане 0.9975391030311584\n",
      "вещи 0.9975258708000183\n",
      "учесници 0.9974690079689026\n",
      "зүйлс 0.9974520206451416\n",
      "обробки 0.9974477291107178\n",
      "байгууллагуудын 0.9974027872085571\n",
      "долбоор 0.9973726272583008\n",
      "фарма 0.9973312616348267\n",
      "вещей 0.9972776174545288\n",
      "власний 0.9972649216651917\n",
      "ствари 0.9972629547119141\n",
      "динг 0.9972625374794006\n",
      "Продукт 0.9972578883171082\n",
      "нинг 0.997209906578064\n",
      "материјала 0.9971902370452881\n",
      "ястия 0.9971784353256226\n",
      "работата 0.9971710443496704\n",
      "матеріалів 0.997165858745575\n",
      "хөдөлмөрийн 0.9971568584442139\n",
      "членів 0.997153639793396\n",
      "дызайн 0.9971397519111633\n",
      "дисциплін 0.9970869421958923\n",
      "съдържанието 0.9970850348472595\n",
      "радови 0.9970662593841553\n",
      "калектыў 0.9970532655715942\n",
      "кинг 0.9970251321792603\n",
      "зберігання 0.9970059394836426\n",
      "нийтийн 0.9970053434371948\n",
      "Матеріали 0.9970045685768127\n",
      "материјали 0.9969939589500427\n",
      "инг 0.9969924688339233\n",
      "материалы 0.9969918727874756\n",
      "уреди 0.9969720244407654\n",
      "трен 0.9969700574874878\n",
      "опрема 0.9969539642333984\n",
      "друштву 0.9969413876533508\n",
      "обществени 0.9969359636306763\n",
      "спрос 0.9969168901443481\n",
      "материали 0.9969159364700317\n",
      "селекција 0.9968990087509155\n",
      "торгівлі 0.996896505355835\n",
      "администрација 0.9968929886817932\n",
      "інг 0.9968839287757874\n",
      "салбарын 0.9968788623809814\n",
      "поръчки 0.9968764781951904\n",
      "линг 0.9968674182891846\n",
      "храна 0.9968622922897339\n",
      "долбоорлор 0.9968557357788086\n",
      "справ 0.996854305267334\n",
      "изпълнението 0.9968538284301758\n",
      "компоненти 0.9968396425247192\n",
      "набавку 0.9968361854553223\n",
      "нещата 0.9968312978744507\n",
      "материала 0.9968286752700806\n",
      "удзельнікаў 0.9968286752700806\n",
      "пројектима 0.9968198537826538\n",
      "асортимент 0.9968128800392151\n",
      "газрууд 0.9968091249465942\n",
      "ажлаа 0.9968061447143555\n",
      "вод 0.9968039393424988\n",
      "позиції 0.9967992305755615\n",
      "Мес 0.9967948198318481\n",
      "сургалтын 0.9967942833900452\n",
      "објекти 0.9967907071113586\n",
      "работилница 0.9967836737632751\n",
      "съхранение 0.9967790842056274\n",
      "хадгала 0.9967714548110962\n",
      "бэлтгэх 0.9967649579048157\n",
      "фінансових 0.9967518448829651\n",
      "нашій 0.9967489242553711\n",
      "њихове 0.9967474937438965\n",
      "місцевих 0.9967472553253174\n",
      "понуде 0.996745765209198\n",
      "намын 0.9967315793037415\n",
      "одржавање 0.9967308044433594\n",
      "предмети 0.9967280626296997\n",
      "набавке 0.9967257380485535\n",
      "эрхлэгч 0.9967234134674072\n",
      "поверхні 0.9967212677001953\n",
      "оролцогч 0.9967189431190491\n",
      "нийгмийн 0.9967174530029297\n",
      "услугите 0.9967103600502014\n",
      "мес 0.9967060089111328\n",
      "підрозділів 0.9966993927955627\n",
      "матеріали 0.996692955493927\n",
      "материалов 0.9966863989830017\n",
      "околности 0.9966839551925659\n",
      "вещ 0.9966777563095093\n",
      "содржина 0.9966753721237183\n",
      "членами 0.9966727495193481\n",
      "конструкции 0.9966698884963989\n",
      "прас 0.9966651201248169\n",
      "корпус 0.996624231338501\n",
      "мэргэжилтнүүд 0.9966192245483398\n",
      "төслүүд 0.996618926525116\n",
      "эдгээр 0.9966161847114563\n",
      "локалне 0.996613621711731\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(results, key=lambda x: -results[x])[:100]:\n",
    "    print(key, results[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designed-museum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T15:15:58.150446Z",
     "start_time": "2021-02-13T15:15:47.317571Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens'\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "soviet-metropolitan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T15:16:11.942688Z",
     "start_time": "2021-02-13T15:16:06.013913Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/xlm-roberta-base-mean-tokens.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dental-importance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T17:23:32.445045Z",
     "start_time": "2021-02-12T17:23:32.443082Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.to_json_file('../models/xmr-roberta-base-mean-tokens.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "binary-placement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:36:42.353855Z",
     "start_time": "2021-02-13T09:36:38.961668Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel, PretrainedConfig\n",
    "\n",
    "model = XLMRobertaModel(PretrainedConfig.from_json_file('../models/xlm-roberta-base-mean-tokens.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "inappropriate-worth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:36:46.912693Z",
     "start_time": "2021-02-13T09:36:46.558030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/xlm-roberta-base-mean-tokens.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "enabling-musical",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:36:47.515682Z",
     "start_time": "2021-02-13T09:36:47.512327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "stock-rolling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:52:36.863646Z",
     "start_time": "2021-02-11T15:50:51.419816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0149b7fe1d4f8c9833957aec2b93d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1112256686.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss = CustomLoss(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "elect-foster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:53:47.205961Z",
     "start_time": "2021-02-11T15:53:45.306289Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "interpreted-optics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:47:44.370535Z",
     "start_time": "2021-02-13T09:47:44.364213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0416,  0.0110, -0.0000,  ...,  0.0000, -0.1096, -0.0141],\n",
       "         [ 0.0631, -0.6998, -0.5704,  ..., -0.1152, -0.4210,  0.5102],\n",
       "         [-0.1585,  0.0000, -0.7146,  ...,  0.6517,  0.3447, -0.1969],\n",
       "         ...,\n",
       "         [-0.0000, -0.1132, -0.4343,  ...,  1.0054, -0.0928, -0.0329],\n",
       "         [ 0.1366,  0.8943,  0.0611,  ...,  0.0495, -0.3360, -0.6585],\n",
       "         [ 0.0166,  0.1572,  0.0089,  ...,  0.0337,  0.0542, -0.1161]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt')\n",
    "\n",
    "model.embeddings(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "tough-nursing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:47:45.325211Z",
     "start_time": "2021-02-13T09:47:45.321214Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1, 1)\n",
    "\n",
    "tokens_one_hot = torch.zeros(inputs.shape[0], 250002).scatter_(\n",
    "    1, inputs, 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "third-gravity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:47:45.897186Z",
     "start_time": "2021-02-13T09:47:45.818972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0416,  0.0000, -0.0678,  ...,  0.0280, -0.1096, -0.0141],\n",
       "         [ 0.0631, -0.6998, -0.5704,  ..., -0.1152, -0.4210,  0.5102],\n",
       "         [-0.1585,  0.4480, -0.7146,  ...,  0.6517,  0.3447, -0.1969],\n",
       "         ...,\n",
       "         [-0.8030, -0.1132, -0.4343,  ...,  1.0054, -0.0928, -0.0329],\n",
       "         [ 0.1366,  0.8943,  0.0611,  ...,  0.0000, -0.3360, -0.6585],\n",
       "         [ 0.0166,  0.1572,  0.0089,  ...,  0.0337,  0.0542, -0.1161]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.forward(inputs_embeds=(tokens_one_hot @ model.embeddings.word_embeddings.weight).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "speaking-second",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:48:20.833661Z",
     "start_time": "2021-02-13T09:48:20.758772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(model.embeddings(inputs), model.embeddings.forward(inputs_embeds=(tokens_one_hot @ model.embeddings.word_embeddings.weight).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "local-vulnerability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:28.581453Z",
     "start_time": "2021-02-13T09:51:28.518050Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt')\n",
    "    \n",
    "    x = model.embeddings(inputs)\n",
    "    \n",
    "    inputs = tokenizer.encode(\"I went fishing and I caught several big fish\", return_tensors='pt').reshape(-1, 1)\n",
    "\n",
    "    tokens_one_hot = torch.zeros(inputs.shape[0], 250002).scatter_(\n",
    "        1, inputs, 1.0\n",
    "    )\n",
    "    \n",
    "    y = model.embeddings.forward(inputs_embeds=(tokens_one_hot @ model.embeddings.word_embeddings.weight).unsqueeze(0))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "confirmed-ethnic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:30.257545Z",
     "start_time": "2021-02-13T09:51:30.255685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "electric-gauge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:31.044750Z",
     "start_time": "2021-02-13T09:51:31.042902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "minimal-integer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T09:51:31.736178Z",
     "start_time": "2021-02-13T09:51:31.733907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((x == y).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-hunger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "diploma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
