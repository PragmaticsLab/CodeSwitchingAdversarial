batch_size: 64
dataset: atis
dropout: 0.1
fp-16: true
ignore_index: 0
languages:
- en
- de
- es
- fr
- ja
- pt
- zh
learning_rate: 1.0e-05
load_adv_pretrained: true
load_checkpoint: false
load_pretrained: true
log: false
log_interval: 50
log_metrics: true
mlm_probability: 0.15
model_name: m-bert
num_epoches: 10
num_examples: 1
num_intent_labels: 23
num_slot_labels: 121
only_english: true
slot_coef: 1.0
