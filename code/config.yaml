batch_size: 16
dataset: atis
dropout: 0.1
fp-16: true
ignore_index: 0
languages:
- en
- de
- es
- fr
- ja
- pt
- zh_cn
learning_rate: 1.0e-05
load_body: false
load_checkpoint: false
load_pretrained: true
log_interval: 50
log_metrics: true
mlm_probability: 0.15
model_name: m-bert
num_epoches: 10
num_intent_labels: 23
num_slot_labels: 143
slot_coef: 1.0
