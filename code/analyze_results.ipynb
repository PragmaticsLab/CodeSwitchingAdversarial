{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:47.116559Z",
     "start_time": "2021-05-13T12:19:45.396746Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:47.124576Z",
     "start_time": "2021-05-13T12:19:47.118471Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_latex(df, caption: str = None):\n",
    "    \n",
    "    def array_fixer(x):\n",
    "        if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "            return f'${np.mean(x):.3f} \\pm {np.std(x):.3f}$'\n",
    "        else:\n",
    "            return f'${x:.3f}$'\n",
    "    \n",
    "    result = \"\"\"\\\n",
    "\\\\begin{{table}}[H]\n",
    "\\t\\\\resizebox{{\\\\textwidth}}{{!}}{{\n",
    "\\t\\t\\\\begin{{tabular}}{{|>{{\\\\bfseries}}l|{}}}\n",
    "\\t\\t\\t\\\\hline\n",
    "{}\n",
    "\\t\\t\\\\end{{tabular}}\n",
    "\\t}}{}\n",
    "\\\\end{{table}}\\\n",
    "\"\"\"\n",
    "\n",
    "    columns = 'c|' * df.shape[1]\n",
    "        \n",
    "    body = ['& ' + ' & '.join(df.columns)]\n",
    "    \n",
    "    body += [\n",
    "        df.index[i] +\n",
    "        '&' + \n",
    "        ' & '.join(map(array_fixer, df.iloc[i].values)) \n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    \n",
    "    for i in range(len(body)):\n",
    "        body[i] = '\\t' * 3 + body[i] + ' \\\\\\\\ \\\\hline'\n",
    "        \n",
    "\n",
    "    body = '\\n'.join(body).replace('_', '\\\\_')\n",
    "    \n",
    "    if caption is not None:\n",
    "        caption = f'\\caption{{{caption}}}'\n",
    "    else:\n",
    "        caption = ''\n",
    "\n",
    "    result = result.format(columns, body, caption)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:47.143604Z",
     "start_time": "2021-05-13T12:19:47.127146Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'xlm-r',\n",
    "    'm-bert',\n",
    "    'xlm-r en',\n",
    "    'm-bert en',\n",
    "    'xlm-r adv',\n",
    "    'm-bert adv',\n",
    "    'xlm-r en + adv',\n",
    "    'm-bert en + adv'\n",
    "]\n",
    "\n",
    "model_args = [\n",
    "    (False, False),\n",
    "    (False, False),\n",
    "    (True, False),\n",
    "    (True, False),\n",
    "    (False, True),\n",
    "    (False, True),\n",
    "    (True, True),\n",
    "    (True, True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:47.152900Z",
     "start_time": "2021-05-13T12:19:47.145178Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_attacks(language, model_name, only_english: bool = False, adv_pretrained: bool = False):\n",
    "    return pd.read_csv(\n",
    "        f'results/{language}/{model_name}_{int(only_english)}_{int(adv_pretrained)}.csv',\n",
    "        index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:21:47.313597Z",
     "start_time": "2021-05-13T12:21:47.290229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_acc</th>\n",
       "      <th>slot_f1</th>\n",
       "      <th>sementic_frame_acc</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No attack</th>\n",
       "      <td>0.978808</td>\n",
       "      <td>0.947356</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.353075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word level [de]</th>\n",
       "      <td>0.909934</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.243709</td>\n",
       "      <td>2.231606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word level [es]</th>\n",
       "      <td>0.876821</td>\n",
       "      <td>0.517572</td>\n",
       "      <td>0.082119</td>\n",
       "      <td>3.328885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word level [fr]</th>\n",
       "      <td>0.872848</td>\n",
       "      <td>0.510785</td>\n",
       "      <td>0.059603</td>\n",
       "      <td>3.951247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word level [ja]</th>\n",
       "      <td>0.817219</td>\n",
       "      <td>0.438087</td>\n",
       "      <td>0.088742</td>\n",
       "      <td>3.204326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word level [pt]</th>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.496828</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>3.891992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word level [zh]</th>\n",
       "      <td>0.855629</td>\n",
       "      <td>0.677183</td>\n",
       "      <td>0.211921</td>\n",
       "      <td>2.211372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alignments [de]</th>\n",
       "      <td>0.948344</td>\n",
       "      <td>0.785827</td>\n",
       "      <td>0.483444</td>\n",
       "      <td>1.437395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alignments [es]</th>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>0.445033</td>\n",
       "      <td>1.226217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alignments [fr]</th>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.755213</td>\n",
       "      <td>0.349669</td>\n",
       "      <td>1.671828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alignments [ja]</th>\n",
       "      <td>0.947020</td>\n",
       "      <td>0.449893</td>\n",
       "      <td>0.115232</td>\n",
       "      <td>4.496914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alignments [pt]</th>\n",
       "      <td>0.941722</td>\n",
       "      <td>0.781093</td>\n",
       "      <td>0.434437</td>\n",
       "      <td>1.366203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alignments [zh]</th>\n",
       "      <td>0.936424</td>\n",
       "      <td>0.624404</td>\n",
       "      <td>0.258278</td>\n",
       "      <td>2.508723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 intent_acc   slot_f1  sementic_frame_acc      loss\n",
       "No attack          0.978808  0.947356            0.854305  0.353075\n",
       "Word level [de]    0.909934  0.694030            0.243709  2.231606\n",
       "Word level [es]    0.876821  0.517572            0.082119  3.328885\n",
       "Word level [fr]    0.872848  0.510785            0.059603  3.951247\n",
       "Word level [ja]    0.817219  0.438087            0.088742  3.204326\n",
       "Word level [pt]    0.860927  0.496828            0.033113  3.891992\n",
       "Word level [zh]    0.855629  0.677183            0.211921  2.211372\n",
       "Alignments [de]    0.948344  0.785827            0.483444  1.437395\n",
       "Alignments [es]    0.937748  0.804100            0.445033  1.226217\n",
       "Alignments [fr]    0.940397  0.755213            0.349669  1.671828\n",
       "Alignments [ja]    0.947020  0.449893            0.115232  4.496914\n",
       "Alignments [pt]    0.941722  0.781093            0.434437  1.366203\n",
       "Alignments [zh]    0.936424  0.624404            0.258278  2.508723"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_attacks('en', 'm-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:47.160329Z",
     "start_time": "2021-05-13T12:19:47.155523Z"
    }
   },
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "\n",
    "index_renamer = {\n",
    "    'intent_acc': 'Intent accuracy',\n",
    "    'slot_f1': 'Slot F1 score',\n",
    "    'sementic_frame_acc': 'Semantic accuracy',\n",
    "    'loss': 'Loss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:47.478099Z",
     "start_time": "2021-05-13T12:19:47.279855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                       xlm-r  xlm-r en  xlm-r adv  xlm-r en + adv\n",
       " Intent accuracy    0.980132  0.901987   0.980132        0.962914\n",
       " Slot F1 score      0.943711  0.870407   0.947758        0.899080\n",
       " Semantic accuracy  0.826490  0.558940   0.842384        0.670199\n",
       " Loss               0.317247  0.729068   0.292712        0.574755,\n",
       " 'm-bert':                      m-bert  m-bert en  m-bert adv  m-bert en + adv\n",
       " Intent accuracy    0.978808   0.952318    0.974834         0.948344\n",
       " Slot F1 score      0.947356   0.899340    0.951906         0.907951\n",
       " Semantic accuracy  0.854305   0.671523    0.846358         0.690066\n",
       " Loss               0.353075   0.584221    0.327805         0.577299}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА ТЕСТОВОЙ ВЫБОРКЕ\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks(language, model_name.split()[0], *model_arg)\n",
    "\n",
    "    output[model_name.split()[0]][model_name] = df.loc['No attack'].to_dict()\n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:48.213704Z",
     "start_time": "2021-05-13T12:19:48.198440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xlm-r</th>\n",
       "      <th>xlm-r en</th>\n",
       "      <th>xlm-r adv</th>\n",
       "      <th>xlm-r en + adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intent accuracy</th>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.901987</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.962914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slot F1 score</th>\n",
       "      <td>0.943711</td>\n",
       "      <td>0.870407</td>\n",
       "      <td>0.947758</td>\n",
       "      <td>0.899080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semantic accuracy</th>\n",
       "      <td>0.826490</td>\n",
       "      <td>0.558940</td>\n",
       "      <td>0.842384</td>\n",
       "      <td>0.670199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.317247</td>\n",
       "      <td>0.729068</td>\n",
       "      <td>0.292712</td>\n",
       "      <td>0.574755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      xlm-r  xlm-r en  xlm-r adv  xlm-r en + adv\n",
       "Intent accuracy    0.980132  0.901987   0.980132        0.962914\n",
       "Slot F1 score      0.943711  0.870407   0.947758        0.899080\n",
       "Semantic accuracy  0.826490  0.558940   0.842384        0.670199\n",
       "Loss               0.317247  0.729068   0.292712        0.574755"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['xlm-r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:48.798458Z",
     "start_time": "2021-05-13T12:19:48.790566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{|>{\\bfseries}l|c|c|c|c|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t& xlm-r & xlm-r en & xlm-r adv & xlm-r en + adv \\\\ \\hline\n",
      "\t\t\tIntent accuracy&$0.980$ & $0.902$ & $0.980$ & $0.963$ \\\\ \\hline\n",
      "\t\t\tSlot F1 score&$0.944$ & $0.870$ & $0.948$ & $0.899$ \\\\ \\hline\n",
      "\t\t\tSemantic accuracy&$0.826$ & $0.559$ & $0.842$ & $0.670$ \\\\ \\hline\n",
      "\t\t\tLoss&$0.317$ & $0.729$ & $0.293$ & $0.575$ \\\\ \\hline\n",
      "\t\t\\end{tabular}\n",
      "\t}\\caption{Таблица сравнения моделей XLM-R между собой на тестовой выборке}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(df_to_latex(output['xlm-r'], 'Таблица сравнения моделей XLM-R между собой на тестовой выборке'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:19:50.753638Z",
     "start_time": "2021-05-13T12:19:50.746374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{|>{\\bfseries}l|c|c|c|c|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t& m-bert & m-bert en & m-bert adv & m-bert en + adv \\\\ \\hline\n",
      "\t\t\tIntent accuracy&$0.979$ & $0.952$ & $0.975$ & $0.948$ \\\\ \\hline\n",
      "\t\t\tSlot F1 score&$0.947$ & $0.899$ & $0.952$ & $0.908$ \\\\ \\hline\n",
      "\t\t\tSemantic accuracy&$0.854$ & $0.672$ & $0.846$ & $0.690$ \\\\ \\hline\n",
      "\t\t\tLoss&$0.353$ & $0.584$ & $0.328$ & $0.577$ \\\\ \\hline\n",
      "\t\t\\end{tabular}\n",
      "\t}\\caption{Таблица сравнения моделей M-BERT между собой на тестовой выборке}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(df_to_latex(output['m-bert'], 'Таблица сравнения моделей M-BERT между собой на тестовой выборке'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:22:25.752503Z",
     "start_time": "2021-05-13T12:22:25.651716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                                                                xlm-r  \\\n",
       " Intent accuracy    [0.933774834437086, 0.8900662251655629, 0.8516...   \n",
       " Slot F1 score      [0.7617957522574081, 0.5970343392299687, 0.604...   \n",
       " Semantic accuracy  [0.343046357615894, 0.1311258278145695, 0.0900...   \n",
       " Loss               [1.6738503978440635, 2.946076341679221, 3.6615...   \n",
       " \n",
       "                                                             xlm-r en  \\\n",
       " Intent accuracy    [0.8079470198675497, 0.7894039735099337, 0.774...   \n",
       " Slot F1 score      [0.6421704201237983, 0.4658109108862009, 0.497...   \n",
       " Semantic accuracy  [0.1920529801324503, 0.0543046357615894, 0.060...   \n",
       " Loss               [2.306877105173312, 3.455510059155916, 3.84072...   \n",
       " \n",
       "                                                            xlm-r adv  \\\n",
       " Intent accuracy    [0.9390728476821192, 0.91523178807947, 0.87549...   \n",
       " Slot F1 score      [0.7783894507745488, 0.6121043570388028, 0.602...   \n",
       " Semantic accuracy  [0.3867549668874172, 0.1417218543046357, 0.084...   \n",
       " Loss               [1.5671113546741635, 2.5669178285096823, 3.418...   \n",
       " \n",
       "                                                       xlm-r en + adv  \n",
       " Intent accuracy    [0.8966887417218543, 0.8741721854304636, 0.839...  \n",
       " Slot F1 score      [0.6580074616553822, 0.5105752391216489, 0.520...  \n",
       " Semantic accuracy  [0.2278145695364238, 0.1006622516556291, 0.070...  \n",
       " Loss               [2.000131011950342, 2.9782749903829475, 3.4907...  ,\n",
       " 'm-bert':                                                               m-bert  \\\n",
       " Intent accuracy    [0.909933774834437, 0.8768211920529801, 0.8728...   \n",
       " Slot F1 score      [0.6940298507462686, 0.5175718849840256, 0.510...   \n",
       " Semantic accuracy  [0.2437086092715231, 0.0821192052980132, 0.059...   \n",
       " Loss               [2.2316064078556863, 3.3288850094142712, 3.951...   \n",
       " \n",
       "                                                            m-bert en  \\\n",
       " Intent accuracy    [0.8158940397350993, 0.7602649006622516, 0.798...   \n",
       " Slot F1 score      [0.5352848928384736, 0.3856853818917551, 0.411...   \n",
       " Semantic accuracy  [0.1271523178807947, 0.0291390728476821, 0.029...   \n",
       " Loss               [2.691404044000726, 3.866874862972059, 3.87324...   \n",
       " \n",
       "                                                           m-bert adv  \\\n",
       " Intent accuracy    [0.8980132450331125, 0.8754966887417218, 0.860...   \n",
       " Slot F1 score      [0.7096611026808296, 0.5240641711229945, 0.534...   \n",
       " Semantic accuracy  [0.2966887417218543, 0.1125827814569536, 0.076...   \n",
       " Loss               [2.0051982909440995, 3.05064112261722, 3.77677...   \n",
       " \n",
       "                                                      m-bert en + adv  \n",
       " Intent accuracy    [0.8317880794701987, 0.8291390728476821, 0.814...  \n",
       " Slot F1 score      [0.5790132036136205, 0.4222972972972972, 0.440...  \n",
       " Semantic accuracy  [0.2172185430463576, 0.0741721854304635, 0.050...  \n",
       " Loss               [2.3013814499503686, 3.268556035192389, 3.6558...  }"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА СРЕДНЕМ ПО АТАКЕ WORD LEVEL\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks(language, model_name.split()[0], *model_arg)\n",
    "    \n",
    "    output[model_name.split()[0]][model_name] = {key: [] for key in df.columns}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if 'Word level' in idx:\n",
    "            for key in df.columns:\n",
    "                output[model_name.split()[0]][model_name][key].append(row[key])\n",
    "    \n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:23:29.135288Z",
     "start_time": "2021-05-13T12:23:29.126605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{|>{\\bfseries}l|c|c|c|c|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t& xlm-r & xlm-r en & xlm-r adv & xlm-r en + adv \\\\ \\hline\n",
      "\t\t\tIntent accuracy&$0.885 \\pm 0.035$ & $0.727 \\pm 0.081$ & $0.893 \\pm 0.037$ & $0.851 \\pm 0.035$ \\\\ \\hline\n",
      "\t\t\tSlot F1 score&$0.642 \\pm 0.080$ & $0.550 \\pm 0.069$ & $0.651 \\pm 0.078$ & $0.568 \\pm 0.065$ \\\\ \\hline\n",
      "\t\t\tSemantic accuracy&$0.179 \\pm 0.097$ & $0.065 \\pm 0.059$ & $0.191 \\pm 0.105$ & $0.089 \\pm 0.067$ \\\\ \\hline\n",
      "\t\t\tLoss&$2.627 \\pm 0.727$ & $3.232 \\pm 0.809$ & $2.424 \\pm 0.667$ & $2.624 \\pm 0.612$ \\\\ \\hline\n",
      "\t\t\\end{tabular}\n",
      "\t}\\caption{Таблица сравнения моделей XLM-R после атаки Word level}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(df_to_latex(output['xlm-r'], 'Таблица сравнения моделей XLM-R после атаки Word level'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:25:14.406973Z",
     "start_time": "2021-05-13T12:25:14.391373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{|>{\\bfseries}l|c|c|c|c|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t& m-bert & m-bert en & m-bert adv & m-bert en + adv \\\\ \\hline\n",
      "\t\t\tIntent accuracy&$0.866 \\pm 0.028$ & $0.771 \\pm 0.032$ & $0.863 \\pm 0.023$ & $0.781 \\pm 0.046$ \\\\ \\hline\n",
      "\t\t\tSlot F1 score&$0.556 \\pm 0.095$ & $0.444 \\pm 0.083$ & $0.585 \\pm 0.086$ & $0.489 \\pm 0.064$ \\\\ \\hline\n",
      "\t\t\tSemantic accuracy&$0.120 \\pm 0.079$ & $0.056 \\pm 0.053$ & $0.145 \\pm 0.088$ & $0.090 \\pm 0.065$ \\\\ \\hline\n",
      "\t\t\tLoss&$3.137 \\pm 0.701$ & $3.335 \\pm 0.662$ & $2.878 \\pm 0.611$ & $3.019 \\pm 0.512$ \\\\ \\hline\n",
      "\t\t\\end{tabular}\n",
      "\t}\\caption{Таблица сравнения моделей M-BERT после атаки Word level}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(df_to_latex(output['m-bert'], 'Таблица сравнения моделей M-BERT после атаки Word level'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:26:41.011476Z",
     "start_time": "2021-05-13T12:26:40.915673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                                                                xlm-r  \\\n",
       " Intent accuracy    [0.9483443708609272, 0.943046357615894, 0.9390...   \n",
       " Slot F1 score      [0.7985016791526738, 0.834794975112586, 0.7515...   \n",
       " Semantic accuracy  [0.5059602649006623, 0.5046357615894039, 0.348...   \n",
       " Loss               [1.362755383904043, 1.083700372472307, 1.69466...   \n",
       " \n",
       "                                                             xlm-r en  \\\n",
       " Intent accuracy    [0.8132450331125828, 0.83841059602649, 0.75894...   \n",
       " Slot F1 score      [0.62045281098957, 0.7008774852826836, 0.56533...   \n",
       " Semantic accuracy  [0.1642384105960264, 0.2317880794701986, 0.092...   \n",
       " Loss               [2.0526277043317496, 1.930259105720018, 2.7359...   \n",
       " \n",
       "                                                            xlm-r adv  \\\n",
       " Intent accuracy    [0.9536423841059604, 0.9562913907284768, 0.936...   \n",
       " Slot F1 score      [0.8142783238489395, 0.8607534573199809, 0.771...   \n",
       " Semantic accuracy  [0.5417218543046357, 0.5589403973509933, 0.365...   \n",
       " Loss               [1.2180307879664105, 0.9568652935031996, 1.674...   \n",
       " \n",
       "                                                       xlm-r en + adv  \n",
       " Intent accuracy    [0.8940397350993378, 0.9006622516556292, 0.864...  \n",
       " Slot F1 score      [0.6834502682624845, 0.7903381642512077, 0.665...  \n",
       " Semantic accuracy  [0.2980132450331126, 0.4132450331125827, 0.222...  \n",
       " Loss               [1.5357540092970197, 1.259629837247102, 1.8258...  ,\n",
       " 'm-bert':                                                               m-bert  \\\n",
       " Intent accuracy    [0.9483443708609272, 0.937748344370861, 0.9403...   \n",
       " Slot F1 score      [0.785827186512118, 0.8040996971814582, 0.7552...   \n",
       " Semantic accuracy  [0.4834437086092715, 0.4450331125827814, 0.349...   \n",
       " Loss               [1.4373949530093293, 1.2262174082625854, 1.671...   \n",
       " \n",
       "                                                            m-bert en  \\\n",
       " Intent accuracy    [0.8105960264900662, 0.8370860927152318, 0.831...   \n",
       " Slot F1 score      [0.5343915343915344, 0.6970019136721242, 0.533...   \n",
       " Semantic accuracy  [0.1218543046357615, 0.2198675496688741, 0.084...   \n",
       " Loss               [2.41340999948351, 1.923210768009487, 2.385733...   \n",
       " \n",
       "                                                           m-bert adv  \\\n",
       " Intent accuracy    [0.9509933774834436, 0.9483443708609272, 0.940...   \n",
       " Slot F1 score      [0.8027763226820326, 0.8518127419922563, 0.785...   \n",
       " Semantic accuracy  [0.5377483443708609, 0.5377483443708609, 0.418...   \n",
       " Loss               [1.317657044980871, 1.0450220570752495, 1.5005...   \n",
       " \n",
       "                                                      m-bert en + adv  \n",
       " Intent accuracy    [0.83841059602649, 0.8635761589403973, 0.84768...  \n",
       " Slot F1 score      [0.6262737537868355, 0.7676720075400565, 0.635...  \n",
       " Semantic accuracy  [0.2516556291390728, 0.3589403973509933, 0.218...  \n",
       " Loss               [1.8400490246321024, 1.4486128789813897, 1.915...  }"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА СРЕДНЕМ ПО АТАКЕ ALIGNMENTS\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks(language, model_name.split()[0], *model_arg)\n",
    "    \n",
    "    output[model_name.split()[0]][model_name] = {key: [] for key in df.columns}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if 'Align' in idx:\n",
    "            for key in df.columns:\n",
    "                output[model_name.split()[0]][model_name][key].append(row[key])\n",
    "    \n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:27:16.579836Z",
     "start_time": "2021-05-13T12:27:16.571830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{|>{\\bfseries}l|c|c|c|c|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t& xlm-r & xlm-r en & xlm-r adv & xlm-r en + adv \\\\ \\hline\n",
      "\t\t\tIntent accuracy&$0.947 \\pm 0.006$ & $0.728 \\pm 0.136$ & $0.954 \\pm 0.009$ & $0.864 \\pm 0.040$ \\\\ \\hline\n",
      "\t\t\tSlot F1 score&$0.708 \\pm 0.140$ & $0.581 \\pm 0.109$ & $0.721 \\pm 0.148$ & $0.641 \\pm 0.129$ \\\\ \\hline\n",
      "\t\t\tSemantic accuracy&$0.366 \\pm 0.156$ & $0.105 \\pm 0.074$ & $0.405 \\pm 0.164$ & $0.228 \\pm 0.138$ \\\\ \\hline\n",
      "\t\t\tLoss&$2.026 \\pm 1.152$ & $2.860 \\pm 0.826$ & $1.992 \\pm 1.248$ & $1.943 \\pm 0.743$ \\\\ \\hline\n",
      "\t\t\\end{tabular}\n",
      "\t}\\caption{Таблица сравнения моделей XLM-R после атаки Alignments}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(df_to_latex(output['xlm-r'], 'Таблица сравнения моделей XLM-R после атаки Alignments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T12:27:16.981636Z",
     "start_time": "2021-05-13T12:27:16.964351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{|>{\\bfseries}l|c|c|c|c|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t& m-bert & m-bert en & m-bert adv & m-bert en + adv \\\\ \\hline\n",
      "\t\t\tIntent accuracy&$0.942 \\pm 0.004$ & $0.828 \\pm 0.020$ & $0.950 \\pm 0.005$ & $0.818 \\pm 0.035$ \\\\ \\hline\n",
      "\t\t\tSlot F1 score&$0.700 \\pm 0.127$ & $0.536 \\pm 0.096$ & $0.728 \\pm 0.137$ & $0.577 \\pm 0.150$ \\\\ \\hline\n",
      "\t\t\tSemantic accuracy&$0.348 \\pm 0.127$ & $0.113 \\pm 0.055$ & $0.406 \\pm 0.158$ & $0.198 \\pm 0.113$ \\\\ \\hline\n",
      "\t\t\tLoss&$2.118 \\pm 1.143$ & $2.474 \\pm 0.591$ & $1.935 \\pm 1.135$ & $2.252 \\pm 0.825$ \\\\ \\hline\n",
      "\t\t\\end{tabular}\n",
      "\t}\\caption{Таблица сравнения моделей M-BERT после атаки Alignments}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(df_to_latex(output['m-bert'], 'Таблица сравнения моделей M-BERT после атаки Alignments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
