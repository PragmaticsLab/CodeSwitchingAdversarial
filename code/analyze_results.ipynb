{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:02.570110Z",
     "start_time": "2021-05-14T17:40:01.526063Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:02.574470Z",
     "start_time": "2021-05-14T17:40:02.570928Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_latex(df, caption: str = None):\n",
    "    \n",
    "    def array_fixer(x):\n",
    "        if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "            return f'${np.mean(x):.3f} \\pm {np.std(x):.3f}$'\n",
    "        else:\n",
    "            return f'${x:.3f}$'\n",
    "    \n",
    "    result = \"\"\"\\\n",
    "\\\\begin{{table}}[H]\n",
    "\\t\\\\resizebox{{\\\\textwidth}}{{!}}{{\n",
    "\\t\\t\\\\begin{{tabular}}{{|>{{\\\\bfseries}}l|{}}}\n",
    "\\t\\t\\t\\\\hline\n",
    "{}\n",
    "\\t\\t\\\\end{{tabular}}\n",
    "\\t}}{}\n",
    "\\\\end{{table}}\\\n",
    "\"\"\"\n",
    "\n",
    "    columns = 'c|' * df.shape[1]\n",
    "        \n",
    "    body = ['& ' + ' & '.join(df.columns)]\n",
    "    \n",
    "    body += [\n",
    "        df.index[i] +\n",
    "        '&' + \n",
    "        ' & '.join(map(array_fixer, df.iloc[i].values)) \n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    \n",
    "    for i in range(len(body)):\n",
    "        body[i] = '\\t' * 3 + body[i] + ' \\\\\\\\ \\\\hline'\n",
    "        \n",
    "\n",
    "    body = '\\n'.join(body).replace('_', '\\\\_')\n",
    "    \n",
    "    if caption is not None:\n",
    "        caption = f'\\caption{{{caption}}}'\n",
    "    else:\n",
    "        caption = ''\n",
    "\n",
    "    result = result.format(columns, body, caption)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "tables_1 = open('tables_1.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:02.900273Z",
     "start_time": "2021-05-14T17:40:02.898243Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'xlm-r',\n",
    "    'm-bert',\n",
    "    'xlm-r en',\n",
    "    'm-bert en',\n",
    "    'xlm-r adv',\n",
    "    'm-bert adv',\n",
    "    'xlm-r en + adv',\n",
    "    'm-bert en + adv'\n",
    "]\n",
    "\n",
    "model_args = [\n",
    "    (False, False),\n",
    "    (False, False),\n",
    "    (True, False),\n",
    "    (True, False),\n",
    "    (False, True),\n",
    "    (False, True),\n",
    "    (True, True),\n",
    "    (True, True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:03.551025Z",
     "start_time": "2021-05-14T17:40:03.549233Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_attacks(language, model_name, only_english: bool = False, adv_pretrained: bool = False):\n",
    "    return pd.read_csv(\n",
    "        f'results/{language}/{model_name}_{int(only_english)}_{int(adv_pretrained)}.csv',\n",
    "        index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:04.339024Z",
     "start_time": "2021-05-14T17:40:04.329847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_acc</th>\n",
       "      <th>slot_f1</th>\n",
       "      <th>sementic_frame_acc</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.978808</td>\n",
       "      <td>0.947356</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.353075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.976159</td>\n",
       "      <td>0.945361</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.323492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0.957616</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.652980</td>\n",
       "      <td>0.606453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.968212</td>\n",
       "      <td>0.925663</td>\n",
       "      <td>0.803974</td>\n",
       "      <td>0.335643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>0.954967</td>\n",
       "      <td>0.935154</td>\n",
       "      <td>0.740397</td>\n",
       "      <td>0.419405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>0.968212</td>\n",
       "      <td>0.924304</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.412778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh</th>\n",
       "      <td>0.956291</td>\n",
       "      <td>0.944663</td>\n",
       "      <td>0.796026</td>\n",
       "      <td>0.453742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    intent_acc   slot_f1  sementic_frame_acc      loss\n",
       "en    0.978808  0.947356            0.854305  0.353075\n",
       "de    0.976159  0.945361            0.854305  0.323492\n",
       "es    0.957616  0.885226            0.652980  0.606453\n",
       "fr    0.968212  0.925663            0.803974  0.335643\n",
       "ja    0.954967  0.935154            0.740397  0.419405\n",
       "pt    0.968212  0.924304            0.807947  0.412778\n",
       "zh    0.956291  0.944663            0.796026  0.453742"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_attacks('test', 'm-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:08.490211Z",
     "start_time": "2021-05-14T17:40:08.488562Z"
    }
   },
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "\n",
    "index_renamer = {\n",
    "    'intent_acc': 'Intent accuracy',\n",
    "    'slot_f1': 'Slot F1 score',\n",
    "    'sementic_frame_acc': 'Semantic accuracy',\n",
    "    'loss': 'Loss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:08.722402Z",
     "start_time": "2021-05-14T17:40:08.706613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                       xlm-r  xlm-r en  xlm-r adv  xlm-r en + adv\n",
       " Intent accuracy    0.980132  0.901987   0.981457        0.928477\n",
       " Slot F1 score      0.943711  0.870407   0.946577        0.888136\n",
       " Semantic accuracy  0.826490  0.558940   0.833113        0.613245\n",
       " Loss               0.317247  0.729068   0.319632        0.621493,\n",
       " 'm-bert':                      m-bert  m-bert en  m-bert adv  m-bert en + adv\n",
       " Intent accuracy    0.978808   0.952318    0.974834         0.958940\n",
       " Slot F1 score      0.947356   0.899340    0.950394         0.899547\n",
       " Semantic accuracy  0.854305   0.671523    0.860927         0.674172\n",
       " Loss               0.353075   0.584221    0.325914         0.567392}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА ТЕСТОВОЙ ВЫБОРКЕ (АНГЛ)\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks(language, model_name.split()[0], *model_arg)\n",
    "\n",
    "    output[model_name.split()[0]][model_name] = df.loc['No attack'].to_dict()\n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:08.875267Z",
     "start_time": "2021-05-14T17:40:08.870547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xlm-r</th>\n",
       "      <th>xlm-r en</th>\n",
       "      <th>xlm-r adv</th>\n",
       "      <th>xlm-r en + adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intent accuracy</th>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.901987</td>\n",
       "      <td>0.981457</td>\n",
       "      <td>0.928477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slot F1 score</th>\n",
       "      <td>0.943711</td>\n",
       "      <td>0.870407</td>\n",
       "      <td>0.946577</td>\n",
       "      <td>0.888136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semantic accuracy</th>\n",
       "      <td>0.826490</td>\n",
       "      <td>0.558940</td>\n",
       "      <td>0.833113</td>\n",
       "      <td>0.613245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.317247</td>\n",
       "      <td>0.729068</td>\n",
       "      <td>0.319632</td>\n",
       "      <td>0.621493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      xlm-r  xlm-r en  xlm-r adv  xlm-r en + adv\n",
       "Intent accuracy    0.980132  0.901987   0.981457        0.928477\n",
       "Slot F1 score      0.943711  0.870407   0.946577        0.888136\n",
       "Semantic accuracy  0.826490  0.558940   0.833113        0.613245\n",
       "Loss               0.317247  0.729068   0.319632        0.621493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['xlm-r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.030674Z",
     "start_time": "2021-05-14T17:40:09.028587Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['xlm-r'],\n",
    "        'Сравнение моделей XLM-R между собой на тестовой выборке (английский язык)'\n",
    "    ),\n",
    "    file=tables_1,\n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.180395Z",
     "start_time": "2021-05-14T17:40:09.178289Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['m-bert'],\n",
    "        'Сравнение моделей M-BERT между собой на тестовой выборке (английский язык)'\n",
    "    ),\n",
    "    file=tables_1,\n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.346852Z",
     "start_time": "2021-05-14T17:40:09.326238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                                                                xlm-r  \\\n",
       " Intent accuracy    [0.976158940397351, 0.9668874172185432, 0.9708...   \n",
       " Slot F1 score      [0.9385574354407836, 0.9075166269293512, 0.924...   \n",
       " Semantic accuracy  [0.8264900662251655, 0.6966887417218544, 0.806...   \n",
       " Loss               [0.3457097543532176, 0.5021671323865456, 0.333...   \n",
       " \n",
       "                                                             xlm-r en  \\\n",
       " Intent accuracy    [0.8754966887417218, 0.8781456953642384, 0.879...   \n",
       " Slot F1 score      [0.6687760678843665, 0.751044776119403, 0.6120...   \n",
       " Semantic accuracy  [0.2503311258278146, 0.3470198675496688, 0.150...   \n",
       " Loss               [1.1868144895685346, 1.21023256772835, 1.25222...   \n",
       " \n",
       "                                                            xlm-r adv  \\\n",
       " Intent accuracy    [0.9735099337748344, 0.9642384105960264, 0.976...   \n",
       " Slot F1 score      [0.9401633259094284, 0.9055847733533684, 0.929...   \n",
       " Semantic accuracy  [0.8317880794701987, 0.6927152317880795, 0.813...   \n",
       " Loss               [0.3537513591385887, 0.5311582064170293, 0.332...   \n",
       " \n",
       "                                                       xlm-r en + adv  \n",
       " Intent accuracy    [0.8900662251655629, 0.9125827814569536, 0.871...  \n",
       " Slot F1 score      [0.7291851851851852, 0.7882149901380672, 0.622...  \n",
       " Semantic accuracy  [0.3973509933774834, 0.4039735099337748, 0.108...  \n",
       " Loss               [0.9317734229035284, 1.1258697358499232, 1.460...  ,\n",
       " 'm-bert':                                                               m-bert  \\\n",
       " Intent accuracy    [0.976158940397351, 0.9576158940397352, 0.9682...   \n",
       " Slot F1 score      [0.9453613203012338, 0.8852261790182868, 0.925...   \n",
       " Semantic accuracy  [0.8543046357615894, 0.6529801324503312, 0.803...   \n",
       " Loss               [0.3234920282333501, 0.6064531269146276, 0.335...   \n",
       " \n",
       "                                                            m-bert en  \\\n",
       " Intent accuracy    [0.8198675496688742, 0.8701986754966887, 0.875...   \n",
       " Slot F1 score      [0.5579399141630901, 0.7831454005934717, 0.534...   \n",
       " Semantic accuracy  [0.1880794701986755, 0.4013245033112583, 0.194...   \n",
       " Loss               [1.4540314508111851, 1.203549745463227, 1.3518...   \n",
       " \n",
       "                                                           m-bert adv  \\\n",
       " Intent accuracy    [0.976158940397351, 0.9642384105960264, 0.9721...   \n",
       " Slot F1 score      [0.9421567056561448, 0.9003592814371258, 0.927...   \n",
       " Semantic accuracy  [0.8543046357615894, 0.6821192052980133, 0.805...   \n",
       " Loss               [0.3124473575661939, 0.48693767612077, 0.32319...   \n",
       " \n",
       "                                                      m-bert en + adv  \n",
       " Intent accuracy    [0.847682119205298, 0.9006622516556292, 0.8927...  \n",
       " Slot F1 score      [0.5657472738935215, 0.7591953338888228, 0.556...  \n",
       " Semantic accuracy  [0.2662251655629139, 0.3655629139072848, 0.264...  \n",
       " Loss               [1.3728781545632764, 1.1609604589445026, 1.254...  }"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА СРЕДНЕМ ПО ОСТАЛЬНЫМ ЯЗЫКАМ\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks('test', model_name.split()[0], *model_arg)\n",
    "    \n",
    "    output[model_name.split()[0]][model_name] = {}\n",
    "    \n",
    "    for key in df.columns:\n",
    "        output[model_name.split()[0]][model_name][key] = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx != language:\n",
    "            for key in df.columns:\n",
    "                output[model_name.split()[0]][model_name][key].append(row[key])\n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.478160Z",
     "start_time": "2021-05-14T17:40:09.471365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xlm-r</th>\n",
       "      <th>xlm-r en</th>\n",
       "      <th>xlm-r adv</th>\n",
       "      <th>xlm-r en + adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intent accuracy</th>\n",
       "      <td>[0.976158940397351, 0.9668874172185432, 0.9708...</td>\n",
       "      <td>[0.8754966887417218, 0.8781456953642384, 0.879...</td>\n",
       "      <td>[0.9735099337748344, 0.9642384105960264, 0.976...</td>\n",
       "      <td>[0.8900662251655629, 0.9125827814569536, 0.871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slot F1 score</th>\n",
       "      <td>[0.9385574354407836, 0.9075166269293512, 0.924...</td>\n",
       "      <td>[0.6687760678843665, 0.751044776119403, 0.6120...</td>\n",
       "      <td>[0.9401633259094284, 0.9055847733533684, 0.929...</td>\n",
       "      <td>[0.7291851851851852, 0.7882149901380672, 0.622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semantic accuracy</th>\n",
       "      <td>[0.8264900662251655, 0.6966887417218544, 0.806...</td>\n",
       "      <td>[0.2503311258278146, 0.3470198675496688, 0.150...</td>\n",
       "      <td>[0.8317880794701987, 0.6927152317880795, 0.813...</td>\n",
       "      <td>[0.3973509933774834, 0.4039735099337748, 0.108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>[0.3457097543532176, 0.5021671323865456, 0.333...</td>\n",
       "      <td>[1.1868144895685346, 1.21023256772835, 1.25222...</td>\n",
       "      <td>[0.3537513591385887, 0.5311582064170293, 0.332...</td>\n",
       "      <td>[0.9317734229035284, 1.1258697358499232, 1.460...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               xlm-r  \\\n",
       "Intent accuracy    [0.976158940397351, 0.9668874172185432, 0.9708...   \n",
       "Slot F1 score      [0.9385574354407836, 0.9075166269293512, 0.924...   \n",
       "Semantic accuracy  [0.8264900662251655, 0.6966887417218544, 0.806...   \n",
       "Loss               [0.3457097543532176, 0.5021671323865456, 0.333...   \n",
       "\n",
       "                                                            xlm-r en  \\\n",
       "Intent accuracy    [0.8754966887417218, 0.8781456953642384, 0.879...   \n",
       "Slot F1 score      [0.6687760678843665, 0.751044776119403, 0.6120...   \n",
       "Semantic accuracy  [0.2503311258278146, 0.3470198675496688, 0.150...   \n",
       "Loss               [1.1868144895685346, 1.21023256772835, 1.25222...   \n",
       "\n",
       "                                                           xlm-r adv  \\\n",
       "Intent accuracy    [0.9735099337748344, 0.9642384105960264, 0.976...   \n",
       "Slot F1 score      [0.9401633259094284, 0.9055847733533684, 0.929...   \n",
       "Semantic accuracy  [0.8317880794701987, 0.6927152317880795, 0.813...   \n",
       "Loss               [0.3537513591385887, 0.5311582064170293, 0.332...   \n",
       "\n",
       "                                                      xlm-r en + adv  \n",
       "Intent accuracy    [0.8900662251655629, 0.9125827814569536, 0.871...  \n",
       "Slot F1 score      [0.7291851851851852, 0.7882149901380672, 0.622...  \n",
       "Semantic accuracy  [0.3973509933774834, 0.4039735099337748, 0.108...  \n",
       "Loss               [0.9317734229035284, 1.1258697358499232, 1.460...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['xlm-r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.640843Z",
     "start_time": "2021-05-14T17:40:09.638277Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['xlm-r'],\n",
    "        'Сравнение моделей XLM-R между собой на тестовой выборке (все языки кроме английского)'\n",
    "    ),\n",
    "    file=tables_1, \n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.812462Z",
     "start_time": "2021-05-14T17:40:09.809848Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['m-bert'],\n",
    "        'Сравнение моделей M-BERT между собой на тестовой выборке (все языки кроме английского)'\n",
    "    ),\n",
    "    file=tables_1, \n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:09.979879Z",
     "start_time": "2021-05-14T17:40:09.978232Z"
    }
   },
   "outputs": [],
   "source": [
    "tables_2 = open('tables_2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:10.315296Z",
     "start_time": "2021-05-14T17:40:10.293324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                                                                xlm-r  \\\n",
       " Intent accuracy    [0.9311258278145697, 0.8768211920529801, 0.849...   \n",
       " Slot F1 score      [0.7666752510945146, 0.5888128148817983, 0.602...   \n",
       " Semantic accuracy  [0.343046357615894, 0.1086092715231788, 0.0860...   \n",
       " Loss               [1.654655853541274, 3.0209231000197563, 3.6366...   \n",
       " \n",
       "                                                             xlm-r en  \\\n",
       " Intent accuracy    [0.8092715231788079, 0.7827814569536424, 0.773...   \n",
       " Slot F1 score      [0.6424162836506894, 0.4669049673363737, 0.499...   \n",
       " Semantic accuracy  [0.2013245033112582, 0.0569536423841059, 0.055...   \n",
       " Loss               [2.3026634461001345, 3.5072542830517417, 3.843...   \n",
       " \n",
       "                                                            xlm-r adv  \\\n",
       " Intent accuracy    [0.9350993377483444, 0.8847682119205298, 0.895...   \n",
       " Slot F1 score      [0.7684491299377619, 0.6085357846355877, 0.590...   \n",
       " Semantic accuracy  [0.3470198675496688, 0.1337748344370861, 0.092...   \n",
       " Loss               [1.6545703055042968, 2.775939372966164, 3.4463...   \n",
       " \n",
       "                                                       xlm-r en + adv  \n",
       " Intent accuracy    [0.8423841059602649, 0.8172185430463577, 0.811...  \n",
       " Slot F1 score      [0.6484079870480303, 0.5093281148075669, 0.508...  \n",
       " Semantic accuracy  [0.2357615894039735, 0.0940397350993377, 0.064...  \n",
       " Loss               [2.1629932064759103, 3.1144009226246885, 3.602...  ,\n",
       " 'm-bert':                                                               m-bert  \\\n",
       " Intent accuracy    [0.8927152317880794, 0.8913907284768212, 0.871...   \n",
       " Slot F1 score      [0.6854618682603612, 0.5169851380042463, 0.509...   \n",
       " Semantic accuracy  [0.2278145695364238, 0.0834437086092715, 0.058...   \n",
       " Loss               [2.319971828084243, 3.262373423576355, 3.97580...   \n",
       " \n",
       "                                                            m-bert en  \\\n",
       " Intent accuracy    [0.8105960264900662, 0.7602649006622516, 0.793...   \n",
       " Slot F1 score      [0.539087737433777, 0.3852021357742181, 0.4191...   \n",
       " Semantic accuracy  [0.1364238410596026, 0.0291390728476821, 0.031...   \n",
       " Loss               [2.6948676884174345, 3.869680971848337, 3.8926...   \n",
       " \n",
       "                                                           m-bert adv  \\\n",
       " Intent accuracy    [0.92317880794702, 0.8940397350993378, 0.89006...   \n",
       " Slot F1 score      [0.7039004794609304, 0.5318711446196024, 0.534...   \n",
       " Semantic accuracy  [0.3019867549668874, 0.1139072847682119, 0.087...   \n",
       " Loss               [1.8939963560355335, 3.0911862285513627, 3.845...   \n",
       " \n",
       "                                                      m-bert en + adv  \n",
       " Intent accuracy    [0.8649006622516556, 0.8278145695364238, 0.854...  \n",
       " Slot F1 score      [0.5310933477848531, 0.4047179195679977, 0.371...  \n",
       " Semantic accuracy  [0.1867549668874172, 0.0728476821192053, 0.035...  \n",
       " Loss               [2.284780972882321, 3.315650954999422, 3.70392...  }"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА СРЕДНЕМ ПО АТАКЕ WORD LEVEL\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks(language, model_name.split()[0], *model_arg)\n",
    "    \n",
    "    output[model_name.split()[0]][model_name] = {key: [] for key in df.columns}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if 'Word level' in idx:\n",
    "            for key in df.columns:\n",
    "                output[model_name.split()[0]][model_name][key].append(row[key])\n",
    "    \n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:10.669298Z",
     "start_time": "2021-05-14T17:40:10.666691Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['xlm-r'],\n",
    "        'Сравнение моделей XLM-R после word-level атаки'\n",
    "    ),\n",
    "    file=tables_2,\n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:10.993770Z",
     "start_time": "2021-05-14T17:40:10.991228Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['m-bert'],\n",
    "        'Сравнение моделей M-BERT после word-level атаки'\n",
    "    ),\n",
    "    file=tables_2,\n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:11.300962Z",
     "start_time": "2021-05-14T17:40:11.278459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xlm-r':                                                                xlm-r  \\\n",
       " Intent accuracy    [0.9536423841059604, 0.9456953642384106, 0.928...   \n",
       " Slot F1 score      [0.8018660101075548, 0.8291751223588396, 0.750...   \n",
       " Semantic accuracy  [0.5112582781456954, 0.5112582781456954, 0.336...   \n",
       " Loss               [1.3409015601108734, 1.1233092033132714, 1.745...   \n",
       " \n",
       "                                                             xlm-r en  \\\n",
       " Intent accuracy    [0.8079470198675497, 0.8357615894039735, 0.740...   \n",
       " Slot F1 score      [0.6265863350852455, 0.7040143128704014, 0.568...   \n",
       " Semantic accuracy  [0.1629139072847682, 0.2291390728476821, 0.099...   \n",
       " Loss               [2.049562258469431, 1.88231446617528, 2.750588...   \n",
       " \n",
       "                                                            xlm-r adv  \\\n",
       " Intent accuracy    [0.9589403973509932, 0.9576158940397352, 0.929...   \n",
       " Slot F1 score      [0.8086155443103672, 0.8473118279569892, 0.770...   \n",
       " Semantic accuracy  [0.5377483443708609, 0.5364238410596026, 0.347...   \n",
       " Loss               [1.2532520539482663, 1.0369605243291804, 1.720...   \n",
       " \n",
       "                                                       xlm-r en + adv  \n",
       " Intent accuracy    [0.8701986754966887, 0.856953642384106, 0.8105...  \n",
       " Slot F1 score      [0.6827810972297664, 0.7756463719766473, 0.647...  \n",
       " Semantic accuracy  [0.3033112582781457, 0.3748344370860927, 0.196...  \n",
       " Loss               [1.6591774696582242, 1.564310547552611, 2.0731...  ,\n",
       " 'm-bert':                                                               m-bert  \\\n",
       " Intent accuracy    [0.9483443708609272, 0.9350993377483444, 0.939...   \n",
       " Slot F1 score      [0.7843085804250853, 0.8039443155452436, 0.758...   \n",
       " Semantic accuracy  [0.4874172185430463, 0.4384105960264901, 0.344...   \n",
       " Loss               [1.4399778340600038, 1.2484640232777515, 1.662...   \n",
       " \n",
       "                                                            m-bert en  \\\n",
       " Intent accuracy    [0.8092715231788079, 0.833112582781457, 0.8344...   \n",
       " Slot F1 score      [0.5391653089359568, 0.6985849558463666, 0.531...   \n",
       " Semantic accuracy  [0.1218543046357615, 0.2185430463576159, 0.084...   \n",
       " Loss               [2.4035415401584226, 1.964982842301068, 2.3403...   \n",
       " \n",
       "                                                           m-bert adv  \\\n",
       " Intent accuracy    [0.9562913907284768, 0.9496688741721856, 0.944...   \n",
       " Slot F1 score      [0.8072821846553966, 0.8480490392549805, 0.790...   \n",
       " Semantic accuracy  [0.5443708609271524, 0.5509933774834437, 0.466...   \n",
       " Loss               [1.3073652405095728, 1.052897787933532, 1.4761...   \n",
       " \n",
       "                                                      m-bert en + adv  \n",
       " Intent accuracy    [0.8463576158940397, 0.8900662251655629, 0.892...  \n",
       " Slot F1 score      [0.6129382984506659, 0.7538388849515709, 0.621...  \n",
       " Semantic accuracy  [0.2543046357615894, 0.3576158940397351, 0.241...  \n",
       " Loss               [1.8741214328690576, 1.4309902160575516, 1.830...  }"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА СРЕДНЕМ ПО АТАКЕ ALIGNMENTS\n",
    "\n",
    "output = {'xlm-r': {}, 'm-bert': {}}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks(language, model_name.split()[0], *model_arg)\n",
    "    \n",
    "    output[model_name.split()[0]][model_name] = {key: [] for key in df.columns}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if 'Align' in idx:\n",
    "            for key in df.columns:\n",
    "                output[model_name.split()[0]][model_name][key].append(row[key])\n",
    "    \n",
    "\n",
    "output['xlm-r'] = pd.DataFrame.from_dict(output['xlm-r']).rename(index=index_renamer)\n",
    "output['m-bert'] = pd.DataFrame.from_dict(output['m-bert']).rename(index=index_renamer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:11.594664Z",
     "start_time": "2021-05-14T17:40:11.592098Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['xlm-r'],\n",
    "        'Сравнение моделей XLM-R после phrase-level атаки'\n",
    "    ),\n",
    "    file=tables_2,\n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:13.057282Z",
     "start_time": "2021-05-14T17:40:13.054630Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_to_latex(\n",
    "        output['m-bert'],\n",
    "        'Сравнение моделей M-BERT после phrase-level атаки'\n",
    "    ),\n",
    "    file=tables_2,\n",
    "    flush=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T17:40:33.222526Z",
     "start_time": "2021-05-14T17:40:33.221004Z"
    }
   },
   "outputs": [],
   "source": [
    "tables_1.close()\n",
    "tables_2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
