{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:29.453825Z",
     "start_time": "2021-05-27T14:42:27.881892Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataset import read_atis\n",
    "from utils import load_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid', font_scale=1.5)\n",
    "plt.rc('font', family='Verdana')\n",
    "\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "data_path = '/home/lesha/diploma/pieces of paper/reports/main/tables/'\n",
    "graph_path = '/home/lesha/diploma/pieces of paper/reports/main/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:29.465160Z",
     "start_time": "2021-05-27T14:42:29.454890Z"
    }
   },
   "outputs": [],
   "source": [
    "label_num = 0\n",
    "graph_num = 0\n",
    "\n",
    "\n",
    "def array_fixer(x):\n",
    "    if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "        return f'${np.mean(x):.3f} \\pm {np.std(x):.3f}$'\n",
    "    else:\n",
    "        return f'${x:.3f}$'\n",
    "\n",
    "\n",
    "def df_to_latex(df, caption: str = None):\n",
    "    result = \"\"\"\\\n",
    "\\\\begin{{table}}[H]\n",
    "\\t\\\\resizebox{{\\\\textwidth}}{{!}}{{\n",
    "\\t\\t\\\\begin{{tabular}}{{|>{{\\\\bfseries}}l|{}}}\n",
    "\\t\\t\\t\\\\hline\n",
    "{}\n",
    "\\t\\t\\\\end{{tabular}}\n",
    "\\t}}{}\n",
    "\\\\end{{table}}\\\n",
    "\"\"\"\n",
    "\n",
    "    columns = 'c|' * df.shape[1]\n",
    "\n",
    "    body = ['& ' + ' & '.join(df.columns)]\n",
    "\n",
    "    body += [\n",
    "        df.index[i] +\n",
    "        '&' +\n",
    "        ' & '.join(map(array_fixer, df.iloc[i].values))\n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "\n",
    "    for i in range(len(body)):\n",
    "        body[i] = '\\t' * 3 + body[i] + ' \\\\\\\\ \\\\hline'\n",
    "\n",
    "    body = '\\n'.join(body).replace('_', '\\\\_')\n",
    "\n",
    "    if caption is not None:\n",
    "        caption = f'\\caption{{{caption}}}'\n",
    "    else:\n",
    "        caption = ''\n",
    "\n",
    "    global label_num\n",
    "\n",
    "    caption += f'\\\\label{{tab:table{label_num}}}'\n",
    "\n",
    "    label_num += 1\n",
    "\n",
    "    result = result.format(columns, body, caption)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def attack_to_latex(original, adv, caption: str = None):\n",
    "    result = \"\"\"\\\n",
    "\\\\begin{{table}}[H]\n",
    "\\t\\\\resizebox{{\\\\textwidth}}{{!}}{{\n",
    "\\t\\t\\\\begin{{tabular}}{{|>{{\\\\bfseries}}l|{}|}}\n",
    "\\t\\t\\t\\\\hline\n",
    "{}\n",
    "\\t\\t\\\\end{{tabular}}\n",
    "\\t}}{}\n",
    "\\\\end{{table}}\\\n",
    "\"\"\"\n",
    "\n",
    "    num_columns = max(len(original.split()), len(adv.split()))\n",
    "\n",
    "    original = original.split() + [' '] * (num_columns - len(original.split()))\n",
    "    adv = adv.split() + [' '] * (num_columns - len(adv.split()))\n",
    "\n",
    "    columns = 'c' * num_columns\n",
    "\n",
    "    body = ['Utterance en &' + ' & '.join(original)]\n",
    "    body += ['Utterance adv &' + ' & '.join(adv)]\n",
    "\n",
    "    for i in range(len(body)):\n",
    "        body[i] = '\\t' * 3 + body[i] + ' \\\\\\\\ \\\\hline'\n",
    "\n",
    "    body = '\\n'.join(body).replace('_', '\\\\_')\n",
    "\n",
    "    if caption is not None:\n",
    "        caption = f'\\caption{{{caption}}}'\n",
    "    else:\n",
    "        caption = ''\n",
    "\n",
    "    global label_num\n",
    "\n",
    "    caption += f'\\\\label{{tab:table{label_num}}}'\n",
    "\n",
    "    label_num += 1\n",
    "\n",
    "    result = result.format(columns, body, caption)\n",
    "\n",
    "    return result\n",
    "\n",
    "def plot_df(df, value, caption):\n",
    "    global graph_num\n",
    "\n",
    "    result = f'''\\\n",
    "\\\\begin{{figure}}[h!]\n",
    "    \\\\centering\n",
    "    \\\\includegraphics[width=\\\\textwidth]{{images/{graph_num}}}\n",
    "    \\\\caption{{{caption}}}\\\\label{{fig:figure{graph_num}}}\n",
    "\\\\end{{figure}}\\\n",
    "'''\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    data = df.reset_index().melt(id_vars='index').rename(\n",
    "        columns={\n",
    "            'value': value,\n",
    "            'index': 'Model name',\n",
    "            'variable': 'Language'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    sns.barplot(x='Language', y=value, hue='Model name', data=data, ax=ax, alpha=0.75, saturation=0.75)\n",
    "\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), borderaxespad=0, ncol=10)\n",
    "    sns.despine(fig)\n",
    "    \n",
    "    fig.savefig(graph_path + f'{graph_num}.pdf',  bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    graph_num += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_dfs(df1, df2, value, caption, first_title, second_title):\n",
    "    global graph_num\n",
    "\n",
    "    result = f'''\\\n",
    "\\\\begin{{figure}}[h!]\n",
    "    \\\\centering\n",
    "    \\\\includegraphics[width=\\\\textwidth]{{images/{graph_num}}}\n",
    "    \\\\caption{{{caption}}}\\\\label{{fig:figure{graph_num}}}\n",
    "\\\\end{{figure}}\\\n",
    "'''\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    data1 = df1.reset_index().melt(id_vars='index').rename(\n",
    "        columns={\n",
    "            'value': value,\n",
    "            'index': 'Model name',\n",
    "            'variable': 'Language'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    data2 = df2.reset_index().melt(id_vars='index').rename(\n",
    "        columns={\n",
    "            'value': value,\n",
    "            'index': 'Model name',\n",
    "            'variable': 'Language'\n",
    "        }\n",
    "    )\n",
    "    sns.barplot(x='Language', y=value, hue='Model name', data=data1, ax=ax, alpha=0.75, saturation=0.75)\n",
    "    leg1 = plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), borderaxespad=0, ncol=10, title=first_title)\n",
    "\n",
    "    sns.barplot(x='Language', y=value, hue='Model name', data=data2, ax=ax, facecolor=(1, 1, 1, 0), linewidth=2.5, edgecolor='.2')\n",
    "    plt.legend()\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    ax.legend(handles[len(df1):], labels[len(df1):], loc='upper center', bbox_to_anchor=(0.5, -0.3), borderaxespad=0, ncol=10, title=second_title)\n",
    "\n",
    "    ax.add_artist(leg1)\n",
    "    sns.despine(fig)\n",
    "\n",
    "    fig.savefig(graph_path + f'{graph_num}.pdf',  bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    graph_num += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:40.394269Z",
     "start_time": "2021-05-27T14:42:40.392134Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'xlm-r',\n",
    "    'm-bert',\n",
    "    'xlm-r en',\n",
    "    'm-bert en',\n",
    "    'xlm-r adv',\n",
    "    'm-bert adv',\n",
    "    'xlm-r en adv',\n",
    "    'm-bert en adv',\n",
    "]\n",
    "\n",
    "model_args = [\n",
    "    (False, False),\n",
    "    (False, False),\n",
    "    (True, False),\n",
    "    (True, False),\n",
    "    (False, True),\n",
    "    (False, True),\n",
    "    (True, True),\n",
    "    (True, True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:41.916084Z",
     "start_time": "2021-05-27T14:42:41.914251Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_attacks(language, model_name, only_english: bool = False, adv_pretrained: bool = False):\n",
    "    return pd.read_csv(\n",
    "        f'results/{language}/{model_name}_{int(only_english)}_{int(adv_pretrained)}.csv',\n",
    "        index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:42.351813Z",
     "start_time": "2021-05-27T14:42:42.350230Z"
    }
   },
   "outputs": [],
   "source": [
    "index_renamer = {\n",
    "    'intent_acc': 'Intent accuracy',\n",
    "    'slot_f1': 'Slots F1 score',\n",
    "    'sementic_frame_acc': 'Semantic accuracy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:47.229059Z",
     "start_time": "2021-05-27T14:42:47.211257Z"
    }
   },
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА ТЕСТОВОЙ ВЫБОРКЕ (БЕЗ ЗАЩИТЫ)\n",
    "\n",
    "output1 = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    if 'adv' in model_name:\n",
    "        continue\n",
    "\n",
    "    df = get_model_attacks('test', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        values = df[key].to_dict()\n",
    "        values['avg'] = np.mean(list(values.values()))\n",
    "        output1[index_renamer[key]][model_name] = values\n",
    "\n",
    "output1 = {key: pd.DataFrame.from_dict(output1[key]).rename(index=index_renamer).transpose() for key in output1.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:48.827629Z",
     "start_time": "2021-05-27T14:42:48.379438Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '1.tex', 'w') as f:\n",
    "    for key in output1.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output1[key],\n",
    "                f'Сравнение моделей между собой \\\\textbf{{на тестовой выборке}} датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам языки тестовых подвыборок, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )\n",
    "\n",
    "        plot_df(output1[key], key, f'Сравнение моделей между собой \\\\textbf{{на тестовой выборке}} датасета MultiAtis++ по метрике \\\\textbf{{{key}}}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:50.779657Z",
     "start_time": "2021-05-27T14:42:50.759553Z"
    }
   },
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПО АТАКЕ WORD LEVEL\n",
    "\n",
    "output2 = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    if 'adv' in model_name:\n",
    "        continue\n",
    "\n",
    "    df = get_model_attacks('en', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        mask = df.index.map(lambda x: 'Word' in x)\n",
    "        values = df[mask][key].to_dict()\n",
    "        values['[avg]'] = np.mean(list(values.values()))\n",
    "        output2[index_renamer[key]][model_name] = {key_[key_.find('[') + 1:key_.find(']')]: values[key_] for key_ in\n",
    "                                                  values.keys()}\n",
    "\n",
    "output2 = {key: pd.DataFrame.from_dict(output2[key]).rename(index=index_renamer).transpose() for key in output2.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:52.155354Z",
     "start_time": "2021-05-27T14:42:51.498657Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '2.tex', 'w') as f:\n",
    "    for key in output2.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output2[key],\n",
    "                f'Сравнение моделей между собой после \\\\textbf{{word-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам встраиваемые языки, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )\n",
    "        \n",
    "        tmp_df = output2[key].copy()\n",
    "\n",
    "        for col in output2[key].columns:\n",
    "            tmp_df[col] = output1[key]['en']\n",
    "\n",
    "        plot_dfs(\n",
    "            tmp_df,\n",
    "            output2[key],\n",
    "            key,\n",
    "            f'Сравнение моделей между собой после \\\\textbf{{word-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}.',\n",
    "            'До атаки',\n",
    "            'После атаки'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:52.280266Z",
     "start_time": "2021-05-27T14:42:52.267378Z"
    }
   },
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПО АТАКЕ ALIGNMENTS\n",
    "\n",
    "output3 = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    if 'adv' in model_name:\n",
    "        continue\n",
    "\n",
    "    df = get_model_attacks('en', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        mask = df.index.map(lambda x: 'Align' in x)\n",
    "        values = df[mask][key].to_dict()\n",
    "        values['[avg]'] = np.mean(list(values.values()))\n",
    "        output3[index_renamer[key]][model_name] = {key_[key_.find('[') + 1:key_.find(']')]: values[key_] for key_ in\n",
    "                                                  values.keys()}\n",
    "\n",
    "output3 = {key: pd.DataFrame.from_dict(output3[key]).rename(index=index_renamer).transpose() for key in output3.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:53.685865Z",
     "start_time": "2021-05-27T14:42:53.091402Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '3.tex', 'w') as f:\n",
    "    for key in output3.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output3[key],\n",
    "                f'Сравнение моделей между собой после \\\\textbf{{phrase-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам встраиваемые языки, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )\n",
    "\n",
    "        tmp_df = output3[key].copy()\n",
    "\n",
    "        for col in output3[key].columns:\n",
    "            tmp_df[col] = output1[key]['en']\n",
    "\n",
    "        plot_dfs(\n",
    "            tmp_df,\n",
    "            output3[key],\n",
    "            key,\n",
    "            f'Сравнение моделей между собой после \\\\textbf{{phrase-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}.',\n",
    "            'До атаки',\n",
    "            'После атаки'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:54.023931Z",
     "start_time": "2021-05-27T14:42:54.010414Z"
    }
   },
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА ТЕСТОВОЙ ВЫБОРКЕ (С ЗАЩИТОЙ)\n",
    "\n",
    "output4 = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    if 'adv' not in model_name:\n",
    "        continue\n",
    "    df = get_model_attacks('test', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        values = df[key].to_dict()\n",
    "        values['avg'] = np.mean(list(values.values()))\n",
    "        output4[index_renamer[key]][model_name] = values\n",
    "\n",
    "output4 = {key: pd.DataFrame.from_dict(output4[key]).rename(index=index_renamer).transpose() for key in output4.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:42:56.026472Z",
     "start_time": "2021-05-27T14:42:55.310567Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '4.tex', 'w') as f:\n",
    "    for key in output4.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output4[key],\n",
    "                f'Сравнение моделей \\\\textbf{{с защитой}} между собой \\\\textbf{{на тестовой выборке}} датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам языки тестовых подвыборок, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )\n",
    "\n",
    "        plot_dfs(\n",
    "            output4[key],\n",
    "            output1[key],\n",
    "            key,\n",
    "            f'Сравнение моделей \\\\textbf{{с защитой}} между собой \\\\textbf{{на тестовой выборке}} датасета MultiAtis++ по метрике \\\\textbf{{{key}}}.',\n",
    "            'С защитой',\n",
    "            'Без защиты'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:43:03.899308Z",
     "start_time": "2021-05-27T14:43:03.882827Z"
    }
   },
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПО АТАКЕ WORD LEVEL\n",
    "\n",
    "output5 = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names[4:], model_args[4:]):\n",
    "    df = get_model_attacks('en', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        mask = df.index.map(lambda x: 'Word' in x)\n",
    "        values = df[mask][key].to_dict()\n",
    "        values['[avg]'] = np.mean(list(values.values()))\n",
    "        output5[index_renamer[key]][model_name] = {key_[key_.find('[') + 1:key_.find(']')]: values[key_] for key_ in\n",
    "                                                  values.keys()}\n",
    "\n",
    "output5 = {key: pd.DataFrame.from_dict(output5[key]).rename(index=index_renamer).transpose() for key in output5.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:43:05.768206Z",
     "start_time": "2021-05-27T14:43:05.093995Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '5.tex', 'w') as f:\n",
    "    for key in output5.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output5[key],\n",
    "                f'Сравнение моделей \\\\textbf{{с защитой}} между собой после \\\\textbf{{word-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам встраиваемые языки, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )\n",
    "        \n",
    "        plot_dfs(\n",
    "            output5[key],\n",
    "            output2[key],\n",
    "            key,\n",
    "            f'Сравнение моделей \\\\textbf{{с защитой}} между собой после \\\\textbf{{word-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}.',\n",
    "            'C защитой',\n",
    "            'Без защиты'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:43:09.307121Z",
     "start_time": "2021-05-27T14:43:09.294590Z"
    }
   },
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПО АТАКЕ ALIGNMENTS\n",
    "\n",
    "output6 = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names[4:], model_args[4:]):\n",
    "    df = get_model_attacks('en', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        mask = df.index.map(lambda x: 'Align' in x)\n",
    "        values = df[mask][key].to_dict()\n",
    "        values['[avg]'] = np.mean(list(values.values()))\n",
    "        output6[index_renamer[key]][model_name] = {key_[key_.find('[') + 1:key_.find(']')]: values[key_] for key_ in\n",
    "                                                  values.keys()}\n",
    "\n",
    "output6 = {key: pd.DataFrame.from_dict(output6[key]).rename(index=index_renamer).transpose() for key in output6.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T14:43:10.463868Z",
     "start_time": "2021-05-27T14:43:09.868620Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '6.tex', 'w') as f:\n",
    "    for key in output6.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output6[key],\n",
    "                f'Сравнение моделей \\\\textbf{{с защитой}} между собой после \\\\textbf{{phrase-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам встраиваемые языки, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )\n",
    "        \n",
    "        plot_dfs(\n",
    "            output6[key],\n",
    "            output3[key],\n",
    "            key,\n",
    "            f'Сравнение моделей \\\\textbf{{с защитой}} между собой после \\\\textbf{{phrase-level}} атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}.',\n",
    "            'С защитой',\n",
    "            'Без защиты'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:48:59.341411Z",
     "start_time": "2021-05-17T11:48:59.160178Z"
    }
   },
   "outputs": [],
   "source": [
    "test = read_atis('test', ['en'])\n",
    "test['len'] = test['utterance'].apply(lambda x: len(x.split()))\n",
    "\n",
    "from adversarial import AdversarialWordLevel\n",
    "from adversarial import AdversarialAlignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:48:59.343935Z",
     "start_time": "2021-05-17T11:48:59.342338Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "from utils import save_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:48:59.351328Z",
     "start_time": "2021-05-17T11:48:59.344622Z"
    }
   },
   "outputs": [],
   "source": [
    "languages = ['de', 'es', 'fr', 'es', 'pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:49:07.854184Z",
     "start_time": "2021-05-17T11:48:59.351985Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '7.tex', 'w') as f:\n",
    "    model_name = 'xlm-r'\n",
    "    model_arg = (False, False)\n",
    "\n",
    "    config = load_config()\n",
    "\n",
    "    config['model_name'] = model_name\n",
    "    config['only_english'] = model_arg[0]\n",
    "    config['load_adv_pretrained'] = model_arg[1]\n",
    "\n",
    "    save_config(config)\n",
    "\n",
    "    f1 = AdversarialWordLevel(base_language='en')\n",
    "    f1.port_model()\n",
    "\n",
    "    for i in range(3):\n",
    "        f1.change_attack_language(np.random.choice(languages))\n",
    "\n",
    "        random = test[test['len'] == 9].sample(1).iloc[0]\n",
    "\n",
    "        adv = ' '.join(\n",
    "            f1.attack(x=[random['utterance']], y_slots=[random['slot_labels']], y_intent=[random['intent']])[0][0]\n",
    "        )\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv, caption=f'Пример {i + 1} атаки модели XLM-RoBERTa (xlm-r) word-level атакой.'\n",
    "        ), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:49:14.153754Z",
     "start_time": "2021-05-17T11:49:07.855906Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '8.tex', 'w') as f:\n",
    "    model_name = 'xlm-r'\n",
    "    model_arg = (False, False)\n",
    "\n",
    "    config = load_config()\n",
    "\n",
    "    config['model_name'] = model_name\n",
    "    config['only_english'] = model_arg[0]\n",
    "    config['load_adv_pretrained'] = model_arg[1]\n",
    "\n",
    "    save_config(config)\n",
    "\n",
    "    f1 = AdversarialAlignments(base_language='en')\n",
    "    f1.port_model()\n",
    "\n",
    "    for i in range(3):\n",
    "        f1.change_attack_language(np.random.choice(languages))\n",
    "\n",
    "        random = test[test['len'] == 9].sample(1).iloc[0]\n",
    "        alignments = [f1.alignments[j] for j in [random.name]]\n",
    "\n",
    "        adv = ' '.join(\n",
    "            f1.attack([random['utterance']], [random['slot_labels']], [random['intent']], alignments)[0][0]\n",
    "        )\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv, caption=f'Пример {i + 1} атаки модели XLM-RoBERTa (xlm-r) phrase-level атакой.'\n",
    "        ), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:49:14.157169Z",
     "start_time": "2021-05-17T11:49:14.154679Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = (test['len'] > 7) & (test['len'] < 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:49:51.916357Z",
     "start_time": "2021-05-17T11:49:14.158377Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '9.tex', 'w') as f:\n",
    "    for model_name, model_arg in zip(model_names, model_args):\n",
    "        if 'm-bert' not in model_name:\n",
    "            continue\n",
    "\n",
    "        config = load_config()\n",
    "\n",
    "        config['model_name'] = model_name.split()[0]\n",
    "        config['only_english'] = model_arg[0]\n",
    "        config['load_adv_pretrained'] = model_arg[1]\n",
    "\n",
    "        save_config(config)\n",
    "\n",
    "        f1 = AdversarialWordLevel(base_language='en', attack_language=np.random.choice(languages))\n",
    "        f1.port_model()\n",
    "\n",
    "        random = test[mask].sample(1).iloc[0]\n",
    "\n",
    "        adv = ' '.join(\n",
    "            f1.attack(x=[random['utterance']], y_slots=[random['slot_labels']], y_intent=[random['intent']])[0][0]\n",
    "        )\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv,\n",
    "            caption=f'Пример атаки модели m-BERT ({model_name}) word-level атакой.'\n",
    "        ), file=f)\n",
    "\n",
    "        f1 = AdversarialAlignments(base_language='en', attack_language=np.random.choice(languages))\n",
    "        f1.port_model()\n",
    "\n",
    "        random = test[mask].sample(1).iloc[0]\n",
    "        alignments = [f1.alignments[j] for j in [random.name]]\n",
    "\n",
    "        adv = ' '.join(\n",
    "            f1.attack([random['utterance']], [random['slot_labels']], [random['intent']], alignments)[0][0]\n",
    "        )\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv,\n",
    "            caption=f'Пример атаки модели m-BERT ({model_name}) phrase-level атакой.'\n",
    "        ), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:50:40.161517Z",
     "start_time": "2021-05-17T11:49:51.917259Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '10.tex', 'w') as f:\n",
    "    for model_name, model_arg in zip(model_names, model_args):\n",
    "        if 'xlm-r' not in model_name:\n",
    "            continue\n",
    "\n",
    "        config = load_config()\n",
    "\n",
    "        config['model_name'] = model_name.split()[0]\n",
    "        config['only_english'] = model_arg[0]\n",
    "        config['load_adv_pretrained'] = model_arg[1]\n",
    "\n",
    "        save_config(config)\n",
    "\n",
    "        f1 = AdversarialWordLevel(base_language='en', attack_language=np.random.choice(languages))\n",
    "        f1.port_model()\n",
    "\n",
    "        random = test[mask].sample(1).iloc[0]\n",
    "\n",
    "        adv = ' '.join(\n",
    "            f1.attack(x=[random['utterance']], y_slots=[random['slot_labels']], y_intent=[random['intent']])[0][0]\n",
    "        )\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv,\n",
    "            caption=f'Пример атаки модели XLM-RoBERTa ({model_name}) word-level атакой.'\n",
    "        ), file=f)\n",
    "\n",
    "        f1 = AdversarialAlignments(base_language='en', attack_language=np.random.choice(languages))\n",
    "        f1.port_model()\n",
    "\n",
    "        random = test[mask].sample(1).iloc[0]\n",
    "        alignments = [f1.alignments[j] for j in [random.name]]\n",
    "\n",
    "        adv = ' '.join(\n",
    "            f1.attack([random['utterance']], [random['slot_labels']], [random['intent']], alignments)[0][0]\n",
    "        )\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv,\n",
    "            caption=f'Пример атаки модели XLM-RoBERTa ({model_name}) phrase-level атакой.'\n",
    "        ), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T11:50:40.229652Z",
     "start_time": "2021-05-17T11:50:40.162433Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/atis/adversarial/adversarial_en.csv', index_col='Unnamed: 0.1').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "train = read_atis('train', ['en'])\n",
    "train['len'] = train['utterance'].apply(lambda x: len(x.split()))\n",
    "\n",
    "with open(data_path + '11.tex', 'w') as f:\n",
    "    for i in range(3):\n",
    "        random = train[train['len'] == 9].sample(1).iloc[0]\n",
    "        adv = np.random.choice(data.loc[random.name]['utterance'].values[[0, 1, 2, 4]])\n",
    "\n",
    "        print(attack_to_latex(\n",
    "            random['utterance'], adv, caption=f'Пример {i + 1} из адверсариальной выборки.'\n",
    "        ), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
