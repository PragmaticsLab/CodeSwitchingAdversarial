{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.490584Z",
     "start_time": "2021-05-15T14:42:34.403041Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "data_path = '/home/lesha/diploma/pieces of paper/reports/main/tables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.495056Z",
     "start_time": "2021-05-15T14:42:35.491567Z"
    }
   },
   "outputs": [],
   "source": [
    "label_num = 0\n",
    "\n",
    "def df_to_latex(df, caption: str = None):\n",
    "    \n",
    "    def array_fixer(x):\n",
    "        if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "            return f'${np.mean(x):.3f} \\pm {np.std(x):.3f}$'\n",
    "        else:\n",
    "            return f'${x:.3f}$'\n",
    "    \n",
    "    result = \"\"\"\\\n",
    "\\\\begin{{table}}[H]\n",
    "\\t\\\\resizebox{{\\\\textwidth}}{{!}}{{\n",
    "\\t\\t\\\\begin{{tabular}}{{|>{{\\\\bfseries}}l|{}}}\n",
    "\\t\\t\\t\\\\hline\n",
    "{}\n",
    "\\t\\t\\\\end{{tabular}}\n",
    "\\t}}{}\n",
    "\\\\end{{table}}\\\n",
    "\"\"\"\n",
    "\n",
    "    columns = 'c|' * df.shape[1]\n",
    "        \n",
    "    body = ['& ' + ' & '.join(df.columns)]\n",
    "    \n",
    "    body += [\n",
    "        df.index[i] +\n",
    "        '&' + \n",
    "        ' & '.join(map(array_fixer, df.iloc[i].values)) \n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    \n",
    "    for i in range(len(body)):\n",
    "        body[i] = '\\t' * 3 + body[i] + ' \\\\\\\\ \\\\hline'\n",
    "        \n",
    "\n",
    "    body = '\\n'.join(body).replace('_', '\\\\_')\n",
    "    \n",
    "    if caption is not None:\n",
    "        caption = f'\\caption{{{caption}}}'\n",
    "    else:\n",
    "        caption = ''\n",
    "        \n",
    "    global label_num\n",
    "        \n",
    "    caption += f'\\\\label{{tab:table{label_num}}}'\n",
    "\n",
    "    label_num += 1\n",
    "\n",
    "    result = result.format(columns, body, caption)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.508592Z",
     "start_time": "2021-05-15T14:42:35.495827Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'xlm-r',\n",
    "    'm-bert',\n",
    "    'xlm-r en',\n",
    "    'm-bert en',\n",
    "    'xlm-r adv',\n",
    "    'm-bert adv',\n",
    "    'xlm-r en + adv',\n",
    "    'm-bert en + adv'\n",
    "]\n",
    "\n",
    "model_args = [\n",
    "    (False, False),\n",
    "    (False, False),\n",
    "    (True, False),\n",
    "    (True, False),\n",
    "    (False, True),\n",
    "    (False, True),\n",
    "    (True, True),\n",
    "    (True, True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.513129Z",
     "start_time": "2021-05-15T14:42:35.509327Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_attacks(language, model_name, only_english: bool = False, adv_pretrained: bool = False):\n",
    "    return pd.read_csv(\n",
    "        f'results/{language}/{model_name}_{int(only_english)}_{int(adv_pretrained)}.csv',\n",
    "        index_col=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.517590Z",
     "start_time": "2021-05-15T14:42:35.513800Z"
    }
   },
   "outputs": [],
   "source": [
    "index_renamer = {\n",
    "    'intent_acc': 'Intent accuracy',\n",
    "    'slot_f1': 'Slots F1 score',\n",
    "    'sementic_frame_acc': 'Semantic accuracy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.541606Z",
     "start_time": "2021-05-15T14:42:35.518250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intent accuracy':                        en        de        es        fr        ja        pt  \\\n",
       " xlm-r            0.980132  0.976159  0.966887  0.970861  0.969536  0.966887   \n",
       " m-bert           0.978808  0.976159  0.957616  0.968212  0.954967  0.968212   \n",
       " xlm-r en         0.901987  0.875497  0.878146  0.879470  0.785430  0.774834   \n",
       " m-bert en        0.952318  0.819868  0.870199  0.875497  0.747020  0.838411   \n",
       " xlm-r adv        0.981457  0.973510  0.964238  0.976159  0.972185  0.966887   \n",
       " m-bert adv       0.974834  0.976159  0.964238  0.972185  0.960265  0.969536   \n",
       " xlm-r en + adv   0.928477  0.890066  0.912583  0.871523  0.789404  0.880795   \n",
       " m-bert en + adv  0.958940  0.847682  0.900662  0.892715  0.719205  0.900662   \n",
       " \n",
       "                        zh  \n",
       " xlm-r            0.964238  \n",
       " m-bert           0.956291  \n",
       " xlm-r en         0.847682  \n",
       " m-bert en        0.815894  \n",
       " xlm-r adv        0.966887  \n",
       " m-bert adv       0.961589  \n",
       " xlm-r en + adv   0.815894  \n",
       " m-bert en + adv  0.758940  ,\n",
       " 'Slots F1 score':                        en        de        es        fr        ja        pt  \\\n",
       " xlm-r            0.943711  0.938557  0.907517  0.924231  0.928918  0.923868   \n",
       " m-bert           0.947356  0.945361  0.885226  0.925663  0.935154  0.924304   \n",
       " xlm-r en         0.870407  0.668776  0.751045  0.612022  0.573139  0.672652   \n",
       " m-bert en        0.899340  0.557940  0.783145  0.534114  0.621519  0.518100   \n",
       " xlm-r adv        0.946577  0.940163  0.905585  0.929329  0.927940  0.928786   \n",
       " m-bert adv       0.950394  0.942157  0.900359  0.927521  0.935022  0.920078   \n",
       " xlm-r en + adv   0.888136  0.729185  0.788215  0.622503  0.447176  0.742906   \n",
       " m-bert en + adv  0.899547  0.565747  0.759195  0.556687  0.416033  0.553678   \n",
       " \n",
       "                        zh  \n",
       " xlm-r            0.941942  \n",
       " m-bert           0.944663  \n",
       " xlm-r en         0.737900  \n",
       " m-bert en        0.679905  \n",
       " xlm-r adv        0.945508  \n",
       " m-bert adv       0.946142  \n",
       " xlm-r en + adv   0.717868  \n",
       " m-bert en + adv  0.603783  ,\n",
       " 'Semantic accuracy':                        en        de        es        fr        ja        pt  \\\n",
       " xlm-r            0.826490  0.826490  0.696689  0.806623  0.739073  0.800000   \n",
       " m-bert           0.854305  0.854305  0.652980  0.803974  0.740397  0.807947   \n",
       " xlm-r en         0.558940  0.250331  0.347020  0.150993  0.000000  0.203974   \n",
       " m-bert en        0.671523  0.188079  0.401325  0.194702  0.051656  0.177483   \n",
       " xlm-r adv        0.833113  0.831788  0.692715  0.813245  0.745695  0.809272   \n",
       " m-bert adv       0.860927  0.854305  0.682119  0.805298  0.737748  0.798675   \n",
       " xlm-r en + adv   0.613245  0.397351  0.403974  0.108609  0.005298  0.418543   \n",
       " m-bert en + adv  0.674172  0.266225  0.365563  0.264901  0.003974  0.278146   \n",
       " \n",
       "                        zh  \n",
       " xlm-r            0.778808  \n",
       " m-bert           0.796026  \n",
       " xlm-r en         0.132450  \n",
       " m-bert en        0.213245  \n",
       " xlm-r adv        0.792053  \n",
       " m-bert adv       0.797351  \n",
       " xlm-r en + adv   0.136424  \n",
       " m-bert en + adv  0.136424  }"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПРОСТО НА ТЕСТОВОЙ ВЫБОРКЕ (АНГЛ)\n",
    "\n",
    "output = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks('test', model_name.split()[0], *model_arg)\n",
    "    \n",
    "    for key in index_renamer.keys():\n",
    "        output[index_renamer[key]][model_name] = df[key].to_dict()\n",
    "\n",
    "output = {key: pd.DataFrame.from_dict(output[key]).rename(index=index_renamer).transpose() for key in output.keys()}\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.545851Z",
     "start_time": "2021-05-15T14:42:35.542596Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '1.tex', 'w') as f:\n",
    "    for key in output.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output[key],\n",
    "                f'Сравнение моделей между собой на тестовой выборке датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам языки тестовых подвыборок, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.571044Z",
     "start_time": "2021-05-15T14:42:35.546579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intent accuracy':                        de        es        fr        ja        pt        zh\n",
       " xlm-r            0.931126  0.876821  0.849007  0.825166  0.900662  0.871523\n",
       " m-bert           0.892715  0.891391  0.871523  0.819868  0.852980  0.851656\n",
       " xlm-r en         0.809272  0.782781  0.773510  0.676821  0.553642  0.728477\n",
       " m-bert en        0.810596  0.760265  0.793377  0.723179  0.760265  0.777483\n",
       " xlm-r adv        0.935099  0.884768  0.895364  0.838411  0.917881  0.856954\n",
       " m-bert adv       0.923179  0.894040  0.890066  0.866225  0.899338  0.884768\n",
       " xlm-r en + adv   0.842384  0.817219  0.811921  0.613245  0.810596  0.720530\n",
       " m-bert en + adv  0.864901  0.827815  0.854305  0.760265  0.855629  0.749669,\n",
       " 'Slots F1 score':                        de        es        fr        ja        pt        zh\n",
       " xlm-r            0.766675  0.588813  0.602636  0.551503  0.597709  0.746898\n",
       " m-bert           0.685462  0.516985  0.509909  0.427834  0.494069  0.684211\n",
       " xlm-r en         0.642416  0.466905  0.499416  0.508277  0.542569  0.640907\n",
       " m-bert en        0.539088  0.385202  0.419195  0.362173  0.390605  0.585037\n",
       " xlm-r adv        0.768449  0.608536  0.590965  0.519163  0.607991  0.743609\n",
       " m-bert adv       0.703900  0.531871  0.534875  0.470119  0.562741  0.685425\n",
       " xlm-r en + adv   0.648408  0.509328  0.508400  0.455320  0.541513  0.662532\n",
       " m-bert en + adv  0.531093  0.404718  0.371309  0.440516  0.417090  0.563148,\n",
       " 'Semantic accuracy':                        de        es        fr        ja        pt        zh\n",
       " xlm-r            0.343046  0.108609  0.086093  0.169536  0.076821  0.278146\n",
       " m-bert           0.227815  0.083444  0.058278  0.080795  0.038411  0.213245\n",
       " xlm-r en         0.201325  0.056954  0.055629  0.013245  0.022517  0.042384\n",
       " m-bert en        0.136424  0.029139  0.031788  0.005298  0.010596  0.115232\n",
       " xlm-r adv        0.347020  0.133775  0.092715  0.099338  0.088742  0.283444\n",
       " m-bert adv       0.301987  0.113907  0.087417  0.120530  0.070199  0.237086\n",
       " xlm-r en + adv   0.235762  0.094040  0.064901  0.011921  0.072848  0.128477\n",
       " m-bert en + adv  0.186755  0.072848  0.035762  0.043709  0.038411  0.109934}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПО АТАКЕ WORD LEVEL\n",
    "\n",
    "output = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks('en', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        mask = df.index.map(lambda x: 'Word' in x)\n",
    "        values = df[mask][key].to_dict()\n",
    "        output[index_renamer[key]][model_name] = {key_[key_.find('[') + 1:key_.find(']')]: values[key_] for key_ in values.keys()}\n",
    "\n",
    "output = {key: pd.DataFrame.from_dict(output[key]).rename(index=index_renamer).transpose() for key in output.keys()}\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.574977Z",
     "start_time": "2021-05-15T14:42:35.571756Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '2.tex', 'w') as f:\n",
    "    for key in output.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output[key],\n",
    "                f'Сравнение моделей между собой после word-level атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам встраиваемые языки, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.602292Z",
     "start_time": "2021-05-15T14:42:35.575654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intent accuracy':                        de        es        fr        ja        pt        zh\n",
       " xlm-r            0.953642  0.945695  0.928477  0.952318  0.964238  0.949669\n",
       " m-bert           0.948344  0.935099  0.939073  0.950993  0.940397  0.933775\n",
       " xlm-r en         0.807947  0.835762  0.740397  0.749669  0.442384  0.784106\n",
       " m-bert en        0.809272  0.833113  0.834437  0.805298  0.860927  0.829139\n",
       " xlm-r adv        0.958940  0.957616  0.929801  0.960265  0.957616  0.947020\n",
       " m-bert adv       0.956291  0.949669  0.944371  0.957616  0.954967  0.945695\n",
       " xlm-r en + adv   0.870199  0.856954  0.810596  0.794702  0.852980  0.776159\n",
       " m-bert en + adv  0.846358  0.890066  0.892715  0.765563  0.900662  0.784106,\n",
       " 'Slots F1 score':                        de        es        fr        ja        pt        zh\n",
       " xlm-r            0.801866  0.829175  0.750731  0.443746  0.813370  0.608960\n",
       " m-bert           0.784309  0.803944  0.758233  0.449928  0.782991  0.619370\n",
       " xlm-r en         0.626586  0.704014  0.568657  0.364769  0.679594  0.560560\n",
       " m-bert en        0.539165  0.698585  0.531226  0.366416  0.530324  0.563190\n",
       " xlm-r adv        0.808616  0.847312  0.770889  0.431993  0.820305  0.617295\n",
       " m-bert adv       0.807282  0.848049  0.790042  0.445657  0.822081  0.635233\n",
       " xlm-r en + adv   0.682781  0.775646  0.647887  0.326389  0.721132  0.569833\n",
       " m-bert en + adv  0.612938  0.753839  0.621278  0.323539  0.630590  0.523289,\n",
       " 'Semantic accuracy':                        de        es        fr        ja        pt        zh\n",
       " xlm-r            0.511258  0.511258  0.336424  0.115232  0.521854  0.209272\n",
       " m-bert           0.487417  0.438411  0.344371  0.113907  0.433113  0.255629\n",
       " xlm-r en         0.162914  0.229139  0.099338  0.013245  0.070199  0.063576\n",
       " m-bert en        0.121854  0.218543  0.084768  0.041060  0.087417  0.105960\n",
       " xlm-r adv        0.537748  0.536424  0.347020  0.140397  0.536424  0.255629\n",
       " m-bert adv       0.544371  0.550993  0.466225  0.136424  0.558940  0.286093\n",
       " xlm-r en + adv   0.303311  0.374834  0.196026  0.007947  0.321854  0.079470\n",
       " m-bert en + adv  0.254305  0.357616  0.241060  0.018543  0.305960  0.108609}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# СРАВНЕНИЕ МОДЕЛЕЙ МЕЖДУ СОБОЙ ПО АТАКЕ ALIGNMENTS\n",
    "\n",
    "output = {index_renamer[key]: {} for key in index_renamer}\n",
    "\n",
    "for model_name, model_arg in zip(model_names, model_args):\n",
    "    df = get_model_attacks('en', model_name.split()[0], *model_arg)\n",
    "\n",
    "    for key in index_renamer.keys():\n",
    "        mask = df.index.map(lambda x: 'Align' in x)\n",
    "        values = df[mask][key].to_dict()\n",
    "        output[index_renamer[key]][model_name] = {key_[key_.find('[') + 1:key_.find(']')]: values[key_] for key_ in values.keys()}\n",
    "\n",
    "output = {key: pd.DataFrame.from_dict(output[key]).rename(index=index_renamer).transpose() for key in output.keys()}\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:42:35.606207Z",
     "start_time": "2021-05-15T14:42:35.602998Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path + '3.tex', 'w') as f:\n",
    "    for key in output.keys():\n",
    "        print(\n",
    "            df_to_latex(\n",
    "                output[key],\n",
    "                f'Сравнение моделей между собой после phrase-level атаки на тестовую выборку датасета MultiAtis++ по метрике \\\\textbf{{{key}}}. По колонкам встраиваемые языки, по рядам тестируемые модели.'\n",
    "            ),\n",
    "            file=f,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
